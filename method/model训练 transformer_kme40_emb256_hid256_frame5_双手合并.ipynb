{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33843159-6e52-4628-831b-d910ff7f054a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/opt/conda/lib/python3.10/site-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import jieba\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ad326e-3de0-4c27-9f91-3fd556d8d7ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#参数列表\n",
    "\n",
    "\n",
    "#模型参数\n",
    "yuan_dim = 42\n",
    "input_dim = 42+181 #输入词汇表大小(等于原词汇表大小+2，+2加的是结束符号和填充符号）\n",
    "emb_dim=256       # 词向量维度\n",
    "hidden_dim=256  # LSTM隐藏层维度\n",
    "output_dim=42+181   # 输出词汇表大小（需你确认）\n",
    "n_layers=1\n",
    "OUTPUT_DIM=42+181 # 输出词汇表大小（需你确认）\n",
    "\n",
    "savepath = '../model/xuanmen_km40/' #模型保存地址\n",
    "savename = 'transformer_kme40_emb256_hid256_frame5_双手合并_词表合并.pth' #模型保存名称\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#数据集参数 \n",
    "data_dir = \"../SLR_dataset/kmeans_40_seq_frame5_双手合并/\"#数据集源文件根目录\n",
    "max_length = 80  # 源序列最大长度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63c54498-cc9c-4f09-90f0-12131fa88eda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.865 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词表大小：223\n"
     ]
    }
   ],
   "source": [
    "npy_files = sorted([f for f in os.listdir(data_dir) if f.endswith(\".npy\")])\n",
    "labels = open(\"../SLR_dataset/corpus.txt\").read().splitlines()  # 假设每行是一个标签\n",
    "labels = [i.split()[1] for i in labels]\n",
    "labels = [i.replace('\\ufeff','') for i in labels]\n",
    "samples = [np.load(os.path.join(data_dir, f),allow_pickle=True) for f in npy_files]\n",
    "\n",
    "# 中文按字符分词（如需分词需修改为jieba等）\n",
    "tokenizer = lambda x: list(jieba.cut(x)) \n",
    "\n",
    "# 构建词表（添加特殊标记）\n",
    "def yield_tokens(texts):\n",
    "    for text in texts:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(\n",
    "    chain(\n",
    "        yield_tokens(labels),          # 原始标签的 token\n",
    "        yield_tokens([str(i) for i in range(42)])  # 数字 0-81\n",
    "    ),\n",
    "    specials=[\"<start>\", \"<pad>\", \"<unk>\", \"<end>\"]\n",
    ")\n",
    "\n",
    "end_token = (vocab['<end>'])     # 源序列结束符号\n",
    "pad_token = (vocab['<pad>'])     # 源填充符号\n",
    "# vocab = build_vocab_from_iterator(\n",
    "#     yield_tokens(labels), \n",
    "#     specials=[\"<start>\",\"<pad>\", \"<unk>\", \"<end>\"]\n",
    "# )\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "# 转换为序列并添加<end>标记\n",
    "sequences = [torch.tensor([vocab[\"<start>\"]]+vocab(tokenizer(text)) + [vocab[\"<end>\"]]) for text in labels]\n",
    "\n",
    "# 统一填充长度（填充<pad>）\n",
    "padded_sequences = pad_sequence(\n",
    "    sequences, \n",
    "    batch_first=True, \n",
    "    padding_value=vocab[\"<pad>\"]\n",
    ")\n",
    "idx2word = vocab.get_itos()\n",
    "\n",
    "\n",
    "sampleslist = []\n",
    "for i in samples:\n",
    "    fenzu = []\n",
    "    for j in i:\n",
    "        shoushi = []\n",
    "        for y in j:\n",
    "            shoushi.append(vocab[str(y)])\n",
    "        fenzu.append(shoushi)\n",
    "    sampleslist.append(fenzu)\n",
    "    \n",
    "samples = np.array(sampleslist,dtype=object)\n",
    "\n",
    "all_data = []\n",
    "for i in range(len(samples)):\n",
    "    input_seq = padded_sequences[i]  # 获取对应的输入序列\n",
    "    for j in samples[i]:\n",
    "        # 将j转为tensor（如果不是）\n",
    "        j_tensor = torch.tensor(j) if not isinstance(j, torch.Tensor) else j.clone().detach()\n",
    "        \n",
    "        # 1. 先添加结束符41（计入1500长度内）\n",
    "        j_with_end = torch.cat([j_tensor, torch.tensor([end_token], dtype=j_tensor.dtype)])\n",
    "        \n",
    "        # 2. 处理长度\n",
    "        if len(j_with_end) > max_length:\n",
    "            # 如果超长：截断到1499再加结束符\n",
    "            j_processed = torch.cat([j_with_end[:max_length-1], \n",
    "                                   torch.tensor([end_token], dtype=j_tensor.dtype)])\n",
    "        elif len(j_with_end) < max_length:\n",
    "            pad_needed = max_length - len(j_with_end)\n",
    "            padding = torch.full((pad_needed,), pad_token, dtype=j_tensor.dtype)\n",
    "            j_processed = torch.cat([j_with_end, padding])\n",
    "        else:\n",
    "            # 刚好1500\n",
    "            j_processed = j_with_end\n",
    "        \n",
    "        # 验证长度\n",
    "        assert len(j_processed) == max_length, f\"长度错误：{len(j_processed)} != {max_length}\"\n",
    "        \n",
    "        # 添加到最终数据\n",
    "        all_data.append([input_seq, j_processed])\n",
    "        \n",
    "print(f'词表大小：{len(vocab.get_stoi())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f006027a-93a5-4a4c-b913-4e6dc6122e6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<start>', '<pad>', '<unk>', '<end>', '的', '是', '他', '我', '你', '我们', '同学', '有', '社会', '国家', '工作', '哥哥', '外祖父', '妈妈', '丈夫', '地位', '基础', '妹妹', '幸福', '提高', '新', '朋友', '爸爸', '目标', '祖父', '稳定', '儿子', '公公', '团结', '困难', '地球', '多', '她', '好', '婆婆', '婚姻', '就业', '形势', '情况', '护士', '改善', '残疾人', '毛毯', '民主', '紧张', '裁缝', '警察', '邻居', '0', '1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '5', '6', '7', '8', '9', '丰富', '事业成功', '事情', '他人', '他们', '任务', '优势', '会计', '保卫', '保姆', '保安', '保育员', '公务员', '农民', '刑警', '前途', '剪刀', '加强', '医生', '卫星', '去', '友谊', '发挥', '向导', '商人', '园丁', '国民', '圆满成功', '坏', '外祖母', '天气预报', '天空', '太阳', '女朋友', '妻子', '姐夫', '姐姐', '嫂嫂', '学生', '安定', '容易', '富强', '导演', '小孩子', '尺子', '局势', '岗位', '岳父', '工人', '干', '平等', '引导', '弟弟', '弱智人', '形成', '律师', '恒星', '成功', '手电筒', '手表', '打火机', '扭转局面', '招呼', '招聘', '拜访', '捐献', '推荐', '搞清', '摆脱', '放弃', '效益', '教师', '教练', '星星', '月亮', '有雨', '来', '杯子', '模特', '橙色', '武警', '歪', '毛巾', '气氛', '没有', '洗脸盆', '深', '演员', '炊事员', '牙刷', '牧民', '猎手', '环境', '现实', '现实情况', '电池', '画家', '疏', '盆', '盲人', '知识分子', '破', '礼貌', '祖母', '空', '经济', '经验丰富', '结果', '绿', '编辑', '美容', '聋人', '职员', '自由恋爱', '茶壶', '行星', '表哥', '被子', '褐色', '观察', '解放军', '记者', '贫苦', '邮递员', '针线', '锋利', '门卫', '项链', '颜色']\n"
     ]
    }
   ],
   "source": [
    "print(vocab.get_itos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73571187-d3c2-4b9b-b706-1a5f91f07660",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 0,  6,  4, 10,  5, 50,  3,  1,  1]),\n",
       " tensor([90, 79, 79, 79, 79, 79, 64, 65, 86, 84, 86, 84, 86, 84, 84, 53, 84, 53,\n",
       "         90, 90, 90, 53, 53, 86, 86, 86, 86, 54, 53, 53, 84, 84, 84, 83, 54, 54,\n",
       "         54, 54, 54, 83, 90, 90, 90,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1,  1,  1,  1,  1,  1,  1])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "851694f0-91db-4d75-8957-477aca740da9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data =all_data \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx][1]\n",
    "        label = self.data[idx][0]\n",
    "        return sample, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ce3f728-720b-429f-ae05-4a78b1e30815",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CustomDataset()\n",
    "# 定义划分比例（例如80%训练，20%测试）\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "# 随机划分\n",
    "train_dataset, test_dataset = random_split(\n",
    "    dataset, \n",
    "    [train_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)  # 固定随机种子确保可复现\n",
    ")\n",
    "\n",
    "# 创建DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "983f04ba-9875-42fd-a5ba-200d658ec951",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def autoregressive_inference(model, src, max_len=50, sos_idx=1, eos_idx=2):\n",
    "    \"\"\"\n",
    "    自回归生成目标序列（测试阶段使用）\n",
    "\n",
    "    Args:\n",
    "        model: TransformerSeq2Seq 模型\n",
    "        src: 源序列 [batch_size, src_len]\n",
    "        max_len: 最大生成长度\n",
    "        sos_idx: 起始符的索引\n",
    "        eos_idx: 结束符的索引\n",
    "    Returns:\n",
    "        outputs: 生成的目标序列 [batch_size, trg_len]\n",
    "    \"\"\"\n",
    "    model.eval()  # 切换到评估模式\n",
    "    device = next(model.parameters()).device\n",
    "    batch_size = src.size(0)\n",
    "\n",
    "    # 初始化目标序列为起始符 [batch_size, 1]\n",
    "    trg = torch.full((batch_size, 1), sos_idx, dtype=torch.long).to(device)\n",
    "\n",
    "    # 逐步生成序列\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_len):\n",
    "            # 前向传播 [batch_size, trg_len, output_dim]\n",
    "            output = model(src, trg)\n",
    "\n",
    "            # 取最后一个时间步的预测 [batch_size, output_dim]\n",
    "            next_token = output[:, -1, :].argmax(dim=-1)\n",
    "\n",
    "            # 将预测的 token 拼接到 trg 中 [batch_size, trg_len + 1]\n",
    "            trg = torch.cat([trg, next_token.unsqueeze(1)], dim=1)\n",
    "\n",
    "            # 如果所有序列都已生成结束符，则提前终止\n",
    "            if (trg == eos_idx).all(dim=-1).any():\n",
    "                break\n",
    "\n",
    "    return trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ba23d39-4889-44d5-9d7c-0e837ac98c56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "\n",
    "class TransformerSeq2Seq(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim, output_dim, n_layers, n_heads=8, dropout=0):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        # Transformer 需要位置编码\n",
    "        self.pos_encoder = PositionalEncoding(emb_dim, dropout)\n",
    "        self.pos_decoder = PositionalEncoding(emb_dim, dropout)\n",
    "        \n",
    "        # 定义 Transformer 结构\n",
    "        self.transformer = Transformer(\n",
    "            d_model=emb_dim,\n",
    "            nhead=n_heads,\n",
    "            num_encoder_layers=n_layers,\n",
    "            num_decoder_layers=n_layers,\n",
    "            dim_feedforward=hidden_dim,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.fc = nn.Linear(emb_dim, output_dim)\n",
    "        self.src_mask = None  # 源序列掩码（可选）\n",
    "        self.trg_mask = None  # 目标序列掩码（用于防止解码器看到未来信息）\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        \"\"\"生成防止解码器看到未来信息的掩码\"\"\"\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask.to(next(self.parameters()).device)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        # src: [batch_size, src_len]\n",
    "        # trg: [batch_size, trg_len]\n",
    "        \n",
    "        # 嵌入 + 位置编码\n",
    "        src_emb = self.pos_encoder(self.embedding(src) * (emb_dim ** 0.5))\n",
    "        trg_emb = self.pos_decoder(self.embedding(trg) * (emb_dim ** 0.5))\n",
    "        \n",
    "        # 调整维度为 [seq_len, batch_size, emb_dim]\n",
    "        src_emb = src_emb.permute(1, 0, 2)\n",
    "        trg_emb = trg_emb.permute(1, 0, 2)\n",
    "        \n",
    "        # 生成目标序列掩码\n",
    "        if self.trg_mask is None or self.trg_mask.size(0) != len(trg_emb):\n",
    "            self.trg_mask = self._generate_square_subsequent_mask(len(trg_emb))\n",
    "        \n",
    "        # Transformer 前向传播\n",
    "        output = self.transformer(\n",
    "            src_emb, \n",
    "            trg_emb,\n",
    "            tgt_mask=self.trg_mask\n",
    "        )\n",
    "        \n",
    "        # 全连接层输出\n",
    "        output = self.fc(output)\n",
    "        return output.permute(1, 0, 2)  # [batch_size, trg_len, output_dim]\n",
    "    def predict(self, src, sos_token_idx=0, eos_token_idx=1, max_len=9, \n",
    "               temperature=1.0, top_k=None):\n",
    "        self.eval()\n",
    "        batch_size = src.size(0)  # 获取输入的实际batch大小\n",
    "\n",
    "        # 初始化trg (batch_size, 1)\n",
    "        trg = torch.full((batch_size, 1), sos_token_idx, \n",
    "                        dtype=torch.long, device=src.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # 编码器处理\n",
    "            src_emb = self.pos_encoder(self.embedding(src) * (self.emb_dim ** 0.5))\n",
    "            src_emb = src_emb.permute(1, 0, 2)  # (seq_len, batch, emb_dim)\n",
    "\n",
    "            for i in range(max_len):\n",
    "                # 解码器处理\n",
    "                trg_emb = self.pos_decoder(self.embedding(trg) * (self.emb_dim ** 0.5))\n",
    "                trg_emb = trg_emb.permute(1, 0, 2)  # (seq_len, batch, emb_dim)\n",
    "\n",
    "                # 生成mask\n",
    "                trg_mask = self._generate_square_subsequent_mask(trg_emb.size(0))\n",
    "\n",
    "                # Transformer前向传播\n",
    "                output = self.transformer(src_emb, trg_emb, tgt_mask=trg_mask)\n",
    "\n",
    "                # 获取最后一个时间步的logits (1, batch, vocab_size)\n",
    "                logits = self.fc(output[-1:, :, :]) / temperature\n",
    "\n",
    "                # Top-k筛选\n",
    "                if top_k is not None:\n",
    "                    v, _ = torch.topk(logits, top_k)\n",
    "                    logits[logits < v[:, :, [-1]]] = -float('Inf')\n",
    "\n",
    "                # 采样 (关键修正点)\n",
    "                probs = F.softmax(logits, dim=-1)  # (1, batch, vocab_size)\n",
    "                pred_token = torch.multinomial(\n",
    "                    probs.squeeze(0),  # (batch, vocab_size)\n",
    "                    num_samples=1\n",
    "                )  # (batch, 1)\n",
    "\n",
    "                # 拼接预测结果 (保持batch维度一致)\n",
    "                trg = torch.cat([trg, pred_token], dim=1)\n",
    "\n",
    "                # 检查是否全部样本都预测了EOS\n",
    "                if (pred_token == eos_token_idx).all():\n",
    "                    break\n",
    "\n",
    "        return trg[:, 1:]  # 去掉起始token\n",
    "#     def predict(self, src, sos_token_idx=0, eos_token_idx=1, max_len=9):\n",
    "#         \"\"\"\n",
    "#         自回归预测方法\n",
    "#         Args:\n",
    "#             src: 源序列 [batch_size, src_len]\n",
    "#             sos_token_idx: 起始符索引 (默认0)\n",
    "#             eos_token_idx: 结束符索引 (默认1)\n",
    "#             max_len: 最大生成长度 (默认9)\n",
    "#         Returns:\n",
    "#             output: 预测的序列 [batch_size, trg_len]\n",
    "#         \"\"\"\n",
    "#         self.eval()  # 确保模型在评估模式\n",
    "#         batch_size = src.size(0)\n",
    "\n",
    "#         # 初始化目标序列为起始符\n",
    "#         trg = torch.full((batch_size, 1), sos_token_idx, dtype=torch.long, device=src.device)\n",
    "\n",
    "#         # 编码器部分\n",
    "#         with torch.no_grad():\n",
    "#             # 嵌入 + 位置编码\n",
    "#             src_emb = self.pos_encoder(self.encoder_embedding(src) * (self.emb_dim ** 0.5))\n",
    "#             src_emb = src_emb.permute(1, 0, 2)  # [seq_len, batch_size, emb_dim]\n",
    "\n",
    "#             # 自回归解码\n",
    "#             for i in range(max_len):\n",
    "#                 # 嵌入 + 位置编码\n",
    "#                 trg_emb = self.pos_decoder(self.decoder_embedding(trg) * (self.emb_dim ** 0.5))\n",
    "#                 trg_emb = trg_emb.permute(1, 0, 2)  # [seq_len, batch_size, emb_dim]\n",
    "\n",
    "#                 # 生成目标序列掩码\n",
    "#                 trg_mask = self._generate_square_subsequent_mask(trg_emb.size(0))\n",
    "\n",
    "#                 # Transformer 前向传播\n",
    "#                 output = self.transformer(\n",
    "#                     src_emb,\n",
    "#                     trg_emb,\n",
    "#                     tgt_mask=trg_mask\n",
    "#                 )\n",
    "\n",
    "#                 # 预测下一个token\n",
    "#                 output = self.fc(output[-1:, :, :])  # 只取最后一个时间步\n",
    "#                 pred_token = output.argmax(-1)  # [1, batch_size]\n",
    "\n",
    "#                 # 将预测的token添加到目标序列\n",
    "#                 trg = torch.cat([trg, pred_token.T], dim=1)\n",
    "\n",
    "#                 # 检查是否所有序列都已生成结束符\n",
    "#                 if (pred_token == eos_token_idx).all():\n",
    "#                     break\n",
    "\n",
    "#         return trg[:, 1:]  # 去掉起始符\n",
    "\n",
    "#     def predict(self, src, sos_token_idx=0, eos_token_idx=1, max_len=9):\n",
    "#         \"\"\"自回归预测\"\"\"\n",
    "#         # 编码器部分\n",
    "#         src_emb = self.pos_encoder(self.encoder_embedding(src) * (self.emb_dim ** 0.5))\n",
    "#         src_emb = src_emb.permute(1, 0, 2)  # [src_seq_len, batch_size, emb_dim]\n",
    "\n",
    "#         batch_size = src.size(0)\n",
    "#         outputs = torch.zeros(batch_size, max_len).long().to(src.device)\n",
    "\n",
    "#         # 初始输入是SOS token\n",
    "#         input = torch.full((batch_size,), sos_token_idx, dtype=torch.long).to(src.device)\n",
    "\n",
    "#         # 存储所有解码器输入\n",
    "#         decoder_inputs = []\n",
    "\n",
    "#         for t in range(max_len):\n",
    "#             # 解码器部分\n",
    "#             trg_emb = self.decoder_embedding(input) * (self.emb_dim ** 0.5)  # [batch_size, emb_dim]\n",
    "#             trg_emb = trg_emb.unsqueeze(1)  # [batch_size, 1, emb_dim]\n",
    "#             decoder_inputs.append(trg_emb)\n",
    "\n",
    "#             # 拼接所有解码器输入\n",
    "#             trg_emb = torch.cat(decoder_inputs, dim=1)  # [batch_size, t+1, emb_dim]\n",
    "#             trg_emb = self.pos_decoder(trg_emb)  # [batch_size, t+1, emb_dim]\n",
    "#             trg_emb = trg_emb.permute(1, 0, 2)  # [t+1, batch_size, emb_dim]\n",
    "\n",
    "#             # 生成当前步的掩码\n",
    "#             self.trg_mask = self._generate_square_subsequent_mask(t + 1).to(src.device)\n",
    "\n",
    "#             output = self.transformer(\n",
    "#                 src_emb,\n",
    "#                 trg_emb,\n",
    "#                 tgt_mask=self.trg_mask\n",
    "#             )  # output shape: [t+1, batch_size, emb_dim]\n",
    "\n",
    "#             # 只取最后一个时间步的预测\n",
    "#             pred = self.fc(output[-1]).argmax(-1)  # [batch_size]\n",
    "#             outputs[:, t] = pred\n",
    "#             input = pred\n",
    "\n",
    "#             if eos_token_idx is not None and (pred == eos_token_idx).all():\n",
    "#                 break\n",
    "\n",
    "#         return outputs\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Transformer 位置编码层\"\"\"\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "184a8000-02f9-41e3-83dc-85370469a06b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "\n",
    "class MultiHeadTransform(nn.Module):\n",
    "    def __init__(self, emb_dim, heads=4):\n",
    "        super().__init__()\n",
    "        self.heads = heads\n",
    "        self.proj = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(emb_dim, emb_dim // heads),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(emb_dim // heads, emb_dim // heads)\n",
    "            ) for _ in range(heads)\n",
    "        ])\n",
    "        self.merge = nn.Linear(emb_dim, emb_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 分头处理 [batch, seq_len, emb_dim] -> [batch, seq_len, heads, emb_dim//heads]\n",
    "        splits = torch.cat([f(x) for f in self.proj], dim=-1)\n",
    "        return self.merge(splits)  # 合并回原维度\n",
    "\n",
    "class TransformerSeq2Seq(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim, output_dim, n_layers, n_heads=8, dropout=0):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.embedding_transform = nn.Sequential(\n",
    "            MultiHeadTransform(emb_dim),\n",
    "            nn.LayerNorm(emb_dim)\n",
    "        )\n",
    "        # Transformer 需要位置编码\n",
    "        self.pos_encoder = PositionalEncoding(emb_dim, dropout)\n",
    "        self.pos_decoder = PositionalEncoding(emb_dim, dropout)\n",
    "        \n",
    "        # 定义 Transformer 结构\n",
    "        self.transformer = Transformer(\n",
    "            d_model=emb_dim,\n",
    "            nhead=n_heads,\n",
    "            num_encoder_layers=n_layers,\n",
    "            num_decoder_layers=n_layers,\n",
    "            dim_feedforward=hidden_dim,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.fc = nn.Linear(emb_dim, output_dim)\n",
    "        self.src_mask = None  # 源序列掩码（可选）\n",
    "        self.trg_mask = None  # 目标序列掩码（用于防止解码器看到未来信息）\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        \"\"\"生成防止解码器看到未来信息的掩码\"\"\"\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask.to(next(self.parameters()).device)\n",
    "    \n",
    "    def _generate_padding_mask(self, seq, pad_idx=1):\n",
    "        \"\"\"生成填充掩码，True表示需要被mask的位置\"\"\"\n",
    "        return (seq == pad_idx).to(next(self.parameters()).device)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        # src: [batch_size, src_len]\n",
    "        # trg: [batch_size, trg_len]\n",
    "        \n",
    "        # 嵌入 + 位置编码\n",
    "        src_emb = self.pos_encoder(self.embedding_transform(self.embedding(src)) * (self.emb_dim ** 0.5))\n",
    "        trg_emb = self.pos_decoder(self.embedding_transform(self.embedding(trg)) * (self.emb_dim ** 0.5))\n",
    "        \n",
    "        # 调整维度为 [seq_len, batch_size, emb_dim]\n",
    "        src_emb = src_emb.permute(1, 0, 2)\n",
    "        trg_emb = trg_emb.permute(1, 0, 2)\n",
    "        \n",
    "        # 生成目标序列掩码（防止看到未来信息）\n",
    "        if self.trg_mask is None or self.trg_mask.size(0) != len(trg_emb):\n",
    "            self.trg_mask = self._generate_square_subsequent_mask(len(trg_emb))\n",
    "        \n",
    "        # 生成填充掩码\n",
    "        src_padding_mask = self._generate_padding_mask(src)  # [batch_size, src_len]\n",
    "        trg_padding_mask = self._generate_padding_mask(trg)  # [batch_size, trg_len]\n",
    "        \n",
    "        # Transformer 前向传播\n",
    "        output = self.transformer(\n",
    "            src_emb, \n",
    "            trg_emb,\n",
    "            src_key_padding_mask=src_padding_mask,\n",
    "            tgt_key_padding_mask=trg_padding_mask,\n",
    "            tgt_mask=self.trg_mask\n",
    "        )\n",
    "        \n",
    "        # 全连接层输出\n",
    "        output = self.fc(output)\n",
    "        return output.permute(1, 0, 2)  # [batch_size, trg_len, output_dim]\n",
    "    \n",
    "    def predict(self, src, sos_token_idx=0, eos_token_idx=1, max_len=9, \n",
    "               temperature=1.0, top_k=None):\n",
    "        self.eval()\n",
    "        batch_size = src.size(0)  # 获取输入的实际batch大小\n",
    "\n",
    "        # 初始化trg (batch_size, 1)\n",
    "        trg = torch.full((batch_size, 1), sos_token_idx, \n",
    "                        dtype=torch.long, device=src.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # 编码器处理\n",
    "            src_emb = self.pos_encoder(self.embedding_transform(self.embedding(src)) * (self.emb_dim ** 0.5))\n",
    "            src_emb = src_emb.permute(1, 0, 2)  # (seq_len, batch, emb_dim)\n",
    "            \n",
    "            # 生成源序列填充掩码\n",
    "            src_padding_mask = self._generate_padding_mask(src)\n",
    "\n",
    "            for i in range(max_len):\n",
    "                # 解码器处理\n",
    "                trg_emb = self.pos_decoder(self.embedding_transform(self.embedding(trg)) * (self.emb_dim ** 0.5))\n",
    "                trg_emb = trg_emb.permute(1, 0, 2)  # (seq_len, batch, emb_dim)\n",
    "\n",
    "                # 生成mask\n",
    "                trg_mask = self._generate_square_subsequent_mask(trg_emb.size(0))\n",
    "                trg_padding_mask = self._generate_padding_mask(trg)\n",
    "\n",
    "                # Transformer前向传播\n",
    "                output = self.transformer(\n",
    "                    src_emb, \n",
    "                    trg_emb, \n",
    "                    src_key_padding_mask=src_padding_mask,\n",
    "                    tgt_key_padding_mask=trg_padding_mask,\n",
    "                    tgt_mask=trg_mask\n",
    "                )\n",
    "\n",
    "                # 获取最后一个时间步的logits (1, batch, vocab_size)\n",
    "                logits = self.fc(output[-1:, :, :]) / temperature\n",
    "\n",
    "                # Top-k筛选\n",
    "                if top_k is not None:\n",
    "                    v, _ = torch.topk(logits, top_k)\n",
    "                    logits[logits < v[:, :, [-1]]] = -float('Inf')\n",
    "\n",
    "                # 采样\n",
    "                probs = F.softmax(logits, dim=-1)  # (1, batch, vocab_size)\n",
    "                pred_token = torch.multinomial(\n",
    "                    probs.squeeze(0),  # (batch, vocab_size)\n",
    "                    num_samples=1\n",
    "                )  # (batch, 1)\n",
    "\n",
    "                # 拼接预测结果 (保持batch维度一致)\n",
    "                trg = torch.cat([trg, pred_token], dim=1)\n",
    "\n",
    "                # 检查是否全部样本都预测了EOS\n",
    "                if (pred_token == eos_token_idx).all():\n",
    "                    break\n",
    "\n",
    "        return trg[:, 1:]  # 去掉起始token\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Transformer 位置编码层\"\"\"\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e22ce0c-536e-4d19-ac83-e9d1edca584b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch.nn import Transformer\n",
    "\n",
    "# class TransformerSeq2Seq(nn.Module):\n",
    "#     def __init__(self, input_dim, emb_dim, hidden_dim, output_dim, n_layers, n_heads=8, dropout=0):\n",
    "#         super().__init__()\n",
    "#         self.emb_dim = emb_dim\n",
    "#         self.encoder_embedding = nn.Embedding(input_dim, emb_dim)\n",
    "#         self.decoder_embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "#         # Transformer 需要位置编码\n",
    "#         self.pos_encoder = PositionalEncoding(emb_dim, dropout)\n",
    "#         self.pos_decoder = PositionalEncoding(emb_dim, dropout)\n",
    "        \n",
    "#         # 定义 Transformer 结构\n",
    "#         self.transformer = Transformer(\n",
    "#             d_model=emb_dim,\n",
    "#             nhead=n_heads,\n",
    "#             num_encoder_layers=n_layers,\n",
    "#             num_decoder_layers=n_layers,\n",
    "#             dim_feedforward=hidden_dim,\n",
    "#             dropout=dropout\n",
    "#         )\n",
    "#         self.fc = nn.Linear(emb_dim, output_dim)\n",
    "#         self.src_mask = None  # 源序列掩码（可选）\n",
    "#         self.trg_mask = None  # 目标序列掩码（用于防止解码器看到未来信息）\n",
    "\n",
    "#     def _generate_square_subsequent_mask(self, sz):\n",
    "#         \"\"\"生成防止解码器看到未来信息的掩码\"\"\"\n",
    "#         mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "#         mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "#         return mask.to(next(self.parameters()).device)\n",
    "\n",
    "#     def forward(self, src, trg):\n",
    "#         # src: [batch_size, src_len]\n",
    "#         # trg: [batch_size, trg_len]\n",
    "        \n",
    "#         # 嵌入 + 位置编码\n",
    "#         src_emb = self.pos_encoder(self.encoder_embedding(src) * (emb_dim ** 0.5))\n",
    "#         trg_emb = self.pos_decoder(self.decoder_embedding(trg) * (emb_dim ** 0.5))\n",
    "        \n",
    "#         # 调整维度为 [seq_len, batch_size, emb_dim]\n",
    "#         src_emb = src_emb.permute(1, 0, 2)\n",
    "#         trg_emb = trg_emb.permute(1, 0, 2)\n",
    "        \n",
    "#         # 生成目标序列掩码\n",
    "#         if self.trg_mask is None or self.trg_mask.size(0) != len(trg_emb):\n",
    "#             self.trg_mask = self._generate_square_subsequent_mask(len(trg_emb))\n",
    "        \n",
    "#         # Transformer 前向传播\n",
    "#         output = self.transformer(\n",
    "#             src_emb, \n",
    "#             trg_emb,\n",
    "#             tgt_mask=self.trg_mask\n",
    "#         )\n",
    "        \n",
    "#         # 全连接层输出\n",
    "#         output = self.fc(output)\n",
    "#         return output.permute(1, 0, 2)  # [batch_size, trg_len, output_dim]\n",
    "#     def predict(self, src, sos_token_idx=0, eos_token_idx=1, max_len=9, \n",
    "#                temperature=1.0, top_k=None):\n",
    "#         self.eval()\n",
    "#         batch_size = src.size(0)  # 获取输入的实际batch大小\n",
    "\n",
    "#         # 初始化trg (batch_size, 1)\n",
    "#         trg = torch.full((batch_size, 1), sos_token_idx, \n",
    "#                         dtype=torch.long, device=src.device)\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             # 编码器处理\n",
    "#             src_emb = self.pos_encoder(self.encoder_embedding(src) * (self.emb_dim ** 0.5))\n",
    "#             src_emb = src_emb.permute(1, 0, 2)  # (seq_len, batch, emb_dim)\n",
    "\n",
    "#             for i in range(max_len):\n",
    "#                 # 解码器处理\n",
    "#                 trg_emb = self.pos_decoder(self.decoder_embedding(trg) * (self.emb_dim ** 0.5))\n",
    "#                 trg_emb = trg_emb.permute(1, 0, 2)  # (seq_len, batch, emb_dim)\n",
    "\n",
    "#                 # 生成mask\n",
    "#                 trg_mask = self._generate_square_subsequent_mask(trg_emb.size(0))\n",
    "\n",
    "#                 # Transformer前向传播\n",
    "#                 output = self.transformer(src_emb, trg_emb, tgt_mask=trg_mask)\n",
    "\n",
    "#                 # 获取最后一个时间步的logits (1, batch, vocab_size)\n",
    "#                 logits = self.fc(output[-1:, :, :]) / temperature\n",
    "\n",
    "#                 # Top-k筛选\n",
    "#                 if top_k is not None:\n",
    "#                     v, _ = torch.topk(logits, top_k)\n",
    "#                     logits[logits < v[:, :, [-1]]] = -float('Inf')\n",
    "\n",
    "#                 # 采样 (关键修正点)\n",
    "#                 probs = F.softmax(logits, dim=-1)  # (1, batch, vocab_size)\n",
    "#                 pred_token = torch.multinomial(\n",
    "#                     probs.squeeze(0),  # (batch, vocab_size)\n",
    "#                     num_samples=1\n",
    "#                 )  # (batch, 1)\n",
    "\n",
    "#                 # 拼接预测结果 (保持batch维度一致)\n",
    "#                 trg = torch.cat([trg, pred_token], dim=1)\n",
    "\n",
    "#                 # 检查是否全部样本都预测了EOS\n",
    "#                 if (pred_token == eos_token_idx).all():\n",
    "#                     break\n",
    "\n",
    "#         return trg[:, 1:]  # 去掉起始token\n",
    "# #     def predict(self, src, sos_token_idx=0, eos_token_idx=1, max_len=9):\n",
    "# #         \"\"\"\n",
    "# #         自回归预测方法\n",
    "# #         Args:\n",
    "# #             src: 源序列 [batch_size, src_len]\n",
    "# #             sos_token_idx: 起始符索引 (默认0)\n",
    "# #             eos_token_idx: 结束符索引 (默认1)\n",
    "# #             max_len: 最大生成长度 (默认9)\n",
    "# #         Returns:\n",
    "# #             output: 预测的序列 [batch_size, trg_len]\n",
    "# #         \"\"\"\n",
    "# #         self.eval()  # 确保模型在评估模式\n",
    "# #         batch_size = src.size(0)\n",
    "\n",
    "# #         # 初始化目标序列为起始符\n",
    "# #         trg = torch.full((batch_size, 1), sos_token_idx, dtype=torch.long, device=src.device)\n",
    "\n",
    "# #         # 编码器部分\n",
    "# #         with torch.no_grad():\n",
    "# #             # 嵌入 + 位置编码\n",
    "# #             src_emb = self.pos_encoder(self.encoder_embedding(src) * (self.emb_dim ** 0.5))\n",
    "# #             src_emb = src_emb.permute(1, 0, 2)  # [seq_len, batch_size, emb_dim]\n",
    "\n",
    "# #             # 自回归解码\n",
    "# #             for i in range(max_len):\n",
    "# #                 # 嵌入 + 位置编码\n",
    "# #                 trg_emb = self.pos_decoder(self.decoder_embedding(trg) * (self.emb_dim ** 0.5))\n",
    "# #                 trg_emb = trg_emb.permute(1, 0, 2)  # [seq_len, batch_size, emb_dim]\n",
    "\n",
    "# #                 # 生成目标序列掩码\n",
    "# #                 trg_mask = self._generate_square_subsequent_mask(trg_emb.size(0))\n",
    "\n",
    "# #                 # Transformer 前向传播\n",
    "# #                 output = self.transformer(\n",
    "# #                     src_emb,\n",
    "# #                     trg_emb,\n",
    "# #                     tgt_mask=trg_mask\n",
    "# #                 )\n",
    "\n",
    "# #                 # 预测下一个token\n",
    "# #                 output = self.fc(output[-1:, :, :])  # 只取最后一个时间步\n",
    "# #                 pred_token = output.argmax(-1)  # [1, batch_size]\n",
    "\n",
    "# #                 # 将预测的token添加到目标序列\n",
    "# #                 trg = torch.cat([trg, pred_token.T], dim=1)\n",
    "\n",
    "# #                 # 检查是否所有序列都已生成结束符\n",
    "# #                 if (pred_token == eos_token_idx).all():\n",
    "# #                     break\n",
    "\n",
    "# #         return trg[:, 1:]  # 去掉起始符\n",
    "\n",
    "# #     def predict(self, src, sos_token_idx=0, eos_token_idx=1, max_len=9):\n",
    "# #         \"\"\"自回归预测\"\"\"\n",
    "# #         # 编码器部分\n",
    "# #         src_emb = self.pos_encoder(self.encoder_embedding(src) * (self.emb_dim ** 0.5))\n",
    "# #         src_emb = src_emb.permute(1, 0, 2)  # [src_seq_len, batch_size, emb_dim]\n",
    "\n",
    "# #         batch_size = src.size(0)\n",
    "# #         outputs = torch.zeros(batch_size, max_len).long().to(src.device)\n",
    "\n",
    "# #         # 初始输入是SOS token\n",
    "# #         input = torch.full((batch_size,), sos_token_idx, dtype=torch.long).to(src.device)\n",
    "\n",
    "# #         # 存储所有解码器输入\n",
    "# #         decoder_inputs = []\n",
    "\n",
    "# #         for t in range(max_len):\n",
    "# #             # 解码器部分\n",
    "# #             trg_emb = self.decoder_embedding(input) * (self.emb_dim ** 0.5)  # [batch_size, emb_dim]\n",
    "# #             trg_emb = trg_emb.unsqueeze(1)  # [batch_size, 1, emb_dim]\n",
    "# #             decoder_inputs.append(trg_emb)\n",
    "\n",
    "# #             # 拼接所有解码器输入\n",
    "# #             trg_emb = torch.cat(decoder_inputs, dim=1)  # [batch_size, t+1, emb_dim]\n",
    "# #             trg_emb = self.pos_decoder(trg_emb)  # [batch_size, t+1, emb_dim]\n",
    "# #             trg_emb = trg_emb.permute(1, 0, 2)  # [t+1, batch_size, emb_dim]\n",
    "\n",
    "# #             # 生成当前步的掩码\n",
    "# #             self.trg_mask = self._generate_square_subsequent_mask(t + 1).to(src.device)\n",
    "\n",
    "# #             output = self.transformer(\n",
    "# #                 src_emb,\n",
    "# #                 trg_emb,\n",
    "# #                 tgt_mask=self.trg_mask\n",
    "# #             )  # output shape: [t+1, batch_size, emb_dim]\n",
    "\n",
    "# #             # 只取最后一个时间步的预测\n",
    "# #             pred = self.fc(output[-1]).argmax(-1)  # [batch_size]\n",
    "# #             outputs[:, t] = pred\n",
    "# #             input = pred\n",
    "\n",
    "# #             if eos_token_idx is not None and (pred == eos_token_idx).all():\n",
    "# #                 break\n",
    "\n",
    "# #         return outputs\n",
    "\n",
    "# class PositionalEncoding(nn.Module):\n",
    "#     \"\"\"Transformer 位置编码层\"\"\"\n",
    "#     def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "#         super().__init__()\n",
    "#         self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "#         pe = torch.zeros(max_len, d_model)\n",
    "#         position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "#         div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "#         pe[:, 0::2] = torch.sin(position * div_term)\n",
    "#         pe[:, 1::2] = torch.cos(position * div_term)\n",
    "#         pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "#         self.register_buffer('pe', pe)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x + self.pe[:x.size(0), :]\n",
    "#         return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b0456b8-baca-486a-808f-9725cdfe40a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def autoregressive_inference(model, src, max_len=9, sos_idx=0, eos_idx=3):\n",
    "    \"\"\"\n",
    "    自回归生成目标序列（测试阶段使用）\n",
    "\n",
    "    Args:\n",
    "        model: TransformerSeq2Seq 模型\n",
    "        src: 源序列 [batch_size, src_len]\n",
    "        max_len: 最大生成长度\n",
    "        sos_idx: 起始符的索引\n",
    "        eos_idx: 结束符的索引\n",
    "    Returns:\n",
    "        outputs: 生成的目标序列 [batch_size, trg_len]\n",
    "    \"\"\"\n",
    "    model.eval()  # 切换到评估模式\n",
    "    device = next(model.parameters()).device\n",
    "    batch_size = src.size(0)\n",
    "\n",
    "    # 初始化目标序列为起始符 [batch_size, 1]\n",
    "    trg = torch.full((batch_size, 1), sos_idx, dtype=torch.long).to(device)\n",
    "\n",
    "    # 逐步生成序列\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_len):\n",
    "            # 前向传播 [batch_size, trg_len, output_dim]\n",
    "            output = model(src, trg)\n",
    "\n",
    "            # 取最后一个时间步的预测 [batch_size, output_dim]\n",
    "            next_token = output[:, -1, :].argmax(dim=-1)\n",
    "\n",
    "            # 将预测的 token 拼接到 trg 中 [batch_size, trg_len + 1]\n",
    "            trg = torch.cat([trg, next_token.unsqueeze(1)], dim=1)\n",
    "\n",
    "            # 如果所有序列都已生成结束符，则提前终止\n",
    "            if (trg == eos_idx).all(dim=-1).any():\n",
    "                break\n",
    "\n",
    "    return trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6609a332-94c0-4029-ab4d-8a8ab37fa6d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_f1(reference, candidate):\n",
    "    # 统计匹配词数\n",
    "    common_terms = set(reference[0]) & set(candidate)\n",
    "    tp = len(common_terms)  # True Positives\n",
    "    fp = len(candidate) - tp  # False Positives\n",
    "    fn = len(reference[0]) - tp  # False Negatives\n",
    "\n",
    "    # 计算精确度、召回率、F1\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    return precision, recall, f1\n",
    "\n",
    "# precision, recall, f1 = calculate_f1(reference, candidate)\n",
    "# print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e216fc86-8282-4021-8b34-b78639e62d34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a00e991b-1f9e-4626-9017-fcd971a8f9c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, epochs, device,test_bool=False):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    max_bleu = 0\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        # print(epoch)\n",
    "        for batch_idx, (src, trg) in enumerate(train_loader):\n",
    "            # print(batch_idx)\n",
    "            src = src.to(device)  # [batch_size, 424]\n",
    "            trg = trg.to(device)  # [batch_size, 10]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 前向传播（模型自动处理teacher forcing）\n",
    "            output = model(src, trg)  # [batch_size, 10, OUTPUT_DIM]\n",
    "            # print('output')\n",
    "            # print(output.argmax(-1))\n",
    "            # # print('trg')\n",
    "            # print(trg)\n",
    "            \n",
    "            # 计算损失（忽略<sos>和padding）\n",
    "            output = output[:, 1:].reshape(-1, OUTPUT_DIM)  # 忽略<sos>，形状变为[batch_size*9, OUTPUT_DIM]\n",
    "            # print(f'output{output.size()}  {output}')\n",
    "            trg = trg[:, 1:].reshape(-1)                    # 忽略<sos>，形状变为[batch_size*9]\n",
    "            # print(f'trg:{trg}')\n",
    "            loss = criterion(output, trg)\n",
    "            # print(output)\n",
    "            # print(output.size())\n",
    "            # print(trg)\n",
    "            # print(trg.size())\n",
    "            # return 0\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f'Epoch: {epoch+1:03d} | Batch: {batch_idx:03d} | Loss: {loss.item():.4f}')\n",
    "        test_num = 0\n",
    "        test_bleu = float(0)\n",
    "        test_loss = 0\n",
    "        test_jingque = 0\n",
    "        test_zhaohui = 0\n",
    "        test_f1 = 0\n",
    "        if test_bool:\n",
    "            for batch_idx , (src,trg) in enumerate(test_loader):\n",
    "                src = src.to(device)\n",
    "                # print(f'src:{src.size()}')\n",
    "                output = model.predict(src)\n",
    "                output = output[0].tolist()\n",
    "                # print([0]+output[:8])\n",
    "                # print(trg.tolist())\n",
    "                score = sentence_bleu(trg.tolist(), [0]+output[:8], weights=(0.5, 0.5)) \n",
    "                precision, recall, f1 = calculate_f1(trg.tolist(), [0]+output[:8])\n",
    "                test_jingque += precision\n",
    "                test_zhaohui += recall\n",
    "                test_f1 += f1\n",
    "                test_num += 1\n",
    "                test_bleu += score\n",
    "        print(f'Epoch: {epoch+1:03d} | Avg Loss: {epoch_loss/len(train_loader):.4f}')\n",
    "        if test_bool:\n",
    "            print(f'test bleu = {test_bleu/test_num},精确率: {(test_jingque/test_num):.4f}, 召回率: {(test_zhaohui/test_num):.4f}, F1: {(test_f1/test_num):.4f}')\n",
    "            if (test_bleu/test_num) > max_bleu:\n",
    "                max_bleu = (test_bleu/test_num)\n",
    "                if not os.path.exists(savepath):\n",
    "                    os.makedirs(savepath)\n",
    "                    print(f\"目录已创建：{savepath}\")\n",
    "                else:\n",
    "                    print(f\"目录已存在：{savepath}\")\n",
    "                torch.save(model,os.path.join(savepath,savename))\n",
    "        print(f'max_bleu={max_bleu}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf162b22-e720-426b-add9-f6188f97ad36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerSeq2Seq(\n",
      "  (embedding): Embedding(223, 256)\n",
      "  (embedding_transform): Sequential(\n",
      "    (0): MultiHeadTransform(\n",
      "      (proj): ModuleList(\n",
      "        (0-3): 4 x Sequential(\n",
      "          (0): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (merge): Linear(in_features=256, out_features=256, bias=True)\n",
      "    )\n",
      "    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (pos_decoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (transformer): Transformer(\n",
      "    (encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0, inplace=False)\n",
      "          (dropout2): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0, inplace=False)\n",
      "          (dropout2): Dropout(p=0, inplace=False)\n",
      "          (dropout3): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=223, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = TransformerSeq2Seq(\n",
    "    input_dim=input_dim,      # 输入词汇表大小\n",
    "    emb_dim=emb_dim,       # 词向量维度\n",
    "    hidden_dim=hidden_dim,    # LSTM隐藏层维度\n",
    "    output_dim=output_dim,     # 输出词汇表大小（需你确认）\n",
    "    n_layers=n_layers\n",
    ").to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da4f0766-e987-4cfd-8279-eec09ad3e02d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 | Batch: 000 | Loss: 5.6409\n",
      "Epoch: 001 | Batch: 100 | Loss: 0.8187\n",
      "Epoch: 001 | Batch: 200 | Loss: 0.1604\n",
      "Epoch: 001 | Batch: 300 | Loss: 0.0443\n",
      "Epoch: 001 | Batch: 400 | Loss: 0.0203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 | Avg Loss: 0.6001\n",
      "test bleu = 0.018475654737950518,精确率: 0.1245, 召回率: 0.1245, F1: 0.1245\n",
      "目录已存在：../model/xuanmen_km40/\n",
      "max_bleu=0.018475654737950518\n",
      "Epoch: 002 | Batch: 000 | Loss: 0.0155\n",
      "Epoch: 002 | Batch: 100 | Loss: 0.0100\n",
      "Epoch: 002 | Batch: 200 | Loss: 0.0074\n",
      "Epoch: 002 | Batch: 300 | Loss: 0.0059\n",
      "Epoch: 002 | Batch: 400 | Loss: 0.0053\n",
      "Epoch: 002 | Avg Loss: 0.0078\n",
      "test bleu = 0.00574712643678161,精确率: 0.1178, 召回率: 0.1178, F1: 0.1178\n",
      "max_bleu=0.018475654737950518\n",
      "Epoch: 003 | Batch: 000 | Loss: 0.0041\n",
      "Epoch: 003 | Batch: 100 | Loss: 0.0033\n",
      "Epoch: 003 | Batch: 200 | Loss: 0.0028\n",
      "Epoch: 003 | Batch: 300 | Loss: 0.0027\n",
      "Epoch: 003 | Batch: 400 | Loss: 0.0021\n",
      "Epoch: 003 | Avg Loss: 0.0029\n",
      "test bleu = 0.011494252873563222,精确率: 0.1149, 召回率: 0.1149, F1: 0.1149\n",
      "max_bleu=0.018475654737950518\n",
      "Epoch: 004 | Batch: 000 | Loss: 0.0021\n",
      "Epoch: 004 | Batch: 100 | Loss: 0.0018\n",
      "Epoch: 004 | Batch: 200 | Loss: 0.0016\n",
      "Epoch: 004 | Batch: 300 | Loss: 0.0014\n",
      "Epoch: 004 | Batch: 400 | Loss: 0.0012\n",
      "Epoch: 004 | Avg Loss: 0.0015\n",
      "test bleu = 0.008620689655172415,精确率: 0.1188, 召回率: 0.1188, F1: 0.1188\n",
      "max_bleu=0.018475654737950518\n",
      "Epoch: 005 | Batch: 000 | Loss: 0.0011\n",
      "Epoch: 005 | Batch: 100 | Loss: 0.0011\n",
      "Epoch: 005 | Batch: 200 | Loss: 0.0010\n",
      "Epoch: 005 | Batch: 300 | Loss: 0.0008\n",
      "Epoch: 005 | Batch: 400 | Loss: 0.0008\n",
      "Epoch: 005 | Avg Loss: 0.0009\n",
      "test bleu = 0.01580459770114943,精确率: 0.1159, 召回率: 0.1159, F1: 0.1159\n",
      "max_bleu=0.018475654737950518\n",
      "Epoch: 006 | Batch: 000 | Loss: 0.0008\n",
      "Epoch: 006 | Batch: 100 | Loss: 0.0007\n",
      "Epoch: 006 | Batch: 200 | Loss: 0.0006\n",
      "Epoch: 006 | Batch: 300 | Loss: 0.0006\n",
      "Epoch: 006 | Batch: 400 | Loss: 0.0005\n",
      "Epoch: 006 | Avg Loss: 0.0006\n",
      "test bleu = 0.008620689655172415,精确率: 0.1178, 召回率: 0.1178, F1: 0.1178\n",
      "max_bleu=0.018475654737950518\n",
      "Epoch: 007 | Batch: 000 | Loss: 0.0006\n",
      "Epoch: 007 | Batch: 100 | Loss: 0.0005\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# print(model)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 你的DataLoader\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 假设填充符index=0\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# criterion=CrossEntropyLoss(), \u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_bool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, criterion, epochs, device, test_bool)\u001b[0m\n\u001b[1;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 前向传播（模型自动处理teacher forcing）\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch_size, 10, OUTPUT_DIM]\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# print('output')\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# print(output.argmax(-1))\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# # print('trg')\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# print(trg)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# 计算损失（忽略<sos>和padding）\u001b[39;00m\n\u001b[1;32m     23\u001b[0m output \u001b[38;5;241m=\u001b[39m output[:, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, OUTPUT_DIM)  \u001b[38;5;66;03m# 忽略<sos>，形状变为[batch_size*9, OUTPUT_DIM]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 66\u001b[0m, in \u001b[0;36mTransformerSeq2Seq.forward\u001b[0;34m(self, src, trg)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, src, trg):\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# src: [batch_size, src_len]\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# trg: [batch_size, trg_len]\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# 嵌入 + 位置编码\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     src_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoder(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_transform(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memb_dim \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m))\n\u001b[1;32m     67\u001b[0m     trg_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_decoder(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_transform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(trg)) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memb_dim \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m))\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# 调整维度为 [seq_len, batch_size, emb_dim]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2264\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2258\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2259\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2260\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2261\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2262\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2263\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# print(model)\n",
    "train(\n",
    "    model=model,\n",
    "    train_loader=train_loader,  # 你的DataLoader\n",
    "    optimizer=optim.Adam(model.parameters(), lr=0.0001),\n",
    "    criterion=CrossEntropyLoss(ignore_index=1),  # 假设填充符index=0\n",
    "    # criterion=CrossEntropyLoss(), \n",
    "    epochs=100,\n",
    "    device=device,\n",
    "    test_bool=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c6f4ec-f6f5-402a-8170-4a0800135b4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(savepath):\n",
    "    os.makedirs(savepath)\n",
    "    print(f\"目录已创建：{savepath}\")\n",
    "else:\n",
    "    print(f\"目录已存在：{savepath}\")\n",
    "torch.save(model,os.path.join(savepath,savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d9a0af-a3fe-47a0-b674-9d89f1a2744b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09c7bf75-033c-49d4-92bb-02e0dc6657a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[162, 8, 8, 8, 182, 182, 182, 182, 182]\n",
      "摆脱你你你炊事员炊事员炊事员炊事员炊事员\n",
      "[2, 8, 8, 8, 8, 8, 8, 8, 8]\n",
      "<unk>你你你你你你你你\n",
      "[21, 21, 21, 21, 21, 21, 21, 21, 21]\n",
      "妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹\n",
      "[14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
      "工作工作工作工作工作工作工作工作工作\n",
      "[152, 152, 152, 152, 152, 152, 152, 152, 152]\n",
      "手电筒手电筒手电筒手电筒手电筒手电筒手电筒手电筒手电筒\n",
      "[148, 148, 148, 148, 148, 148, 148, 148, 152]\n",
      "形成形成形成形成形成形成形成形成手电筒\n",
      "[36, 36, 36, 36, 36, 36, 36, 36, 36]\n",
      "她她她她她她她她她\n",
      "[120, 120, 120, 120, 120, 120, 120, 120, 120]\n",
      "国民国民国民国民国民国民国民国民国民\n",
      "[170, 170, 108, 108, 108, 108, 201, 201, 99]\n",
      "来来刑警刑警刑警刑警结果结果任务\n",
      "[72, 58, 110, 97, 97, 79, 126, 126, 126]\n",
      "2714剪刀他人他人33太阳太阳太阳\n",
      "[152, 152, 152, 152, 152, 152, 152, 153, 219]\n",
      "手电筒手电筒手电筒手电筒手电筒手电筒手电筒手表锋利\n",
      "[41, 41, 41, 41, 41, 41, 41, 41, 41]\n",
      "形势形势形势形势形势形势形势形势形势\n",
      "[13, 13, 13, 13, 13, 13, 13, 13, 13]\n",
      "国家国家国家国家国家国家国家国家国家\n",
      "[16, 37, 111, 111, 111, 111, 111, 129, 129]\n",
      "外祖父好加强加强加强加强加强姐夫姐夫\n",
      "[26, 26, 26, 26, 26, 26, 91, 99, 99]\n",
      "爸爸爸爸爸爸爸爸爸爸爸爸7任务任务\n",
      "[201, 201, 201, 201, 201, 201, 201, 201, 201]\n",
      "结果结果结果结果结果结果结果结果结果\n",
      "[198, 103, 103, 10, 10, 10, 10, 10, 10]\n",
      "空保姆保姆同学同学同学同学同学同学\n",
      "[171, 171, 171, 171, 171, 171, 171, 171, 171]\n",
      "杯子杯子杯子杯子杯子杯子杯子杯子杯子\n",
      "[7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "我我我我我我我我我\n",
      "[187, 187, 187, 187, 2, 47, 129, 102, 12]\n",
      "现实现实现实现实<unk>民主姐夫保卫社会\n",
      "[4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "的的的的的的的的的\n",
      "[194, 194, 194, 194, 33, 22, 22, 22, 22]\n",
      "知识分子知识分子知识分子知识分子困难幸福幸福幸福幸福\n",
      "[4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "的的的的的的的的的\n",
      "[132, 132, 109, 136, 12, 12, 12, 12, 12]\n",
      "学生学生前途导演社会社会社会社会社会\n",
      "[115, 164, 4, 4, 4, 4, 4, 4, 4]\n",
      "友谊效益的的的的的的的\n",
      "[162, 197, 197, 197, 197, 197, 197, 197, 39]\n",
      "摆脱祖母祖母祖母祖母祖母祖母祖母婚姻\n",
      "[54, 208, 208, 208, 208, 208, 208, 208, 208]\n",
      "10茶壶茶壶茶壶茶壶茶壶茶壶茶壶茶壶\n",
      "[148, 148, 148, 148, 148, 148, 148, 148, 148]\n",
      "形成形成形成形成形成形成形成形成形成\n",
      "[148, 148, 148, 148, 148, 148, 148, 148, 148]\n",
      "形成形成形成形成形成形成形成形成形成\n",
      "[36, 36, 36, 36, 36, 36, 36, 36, 36]\n",
      "她她她她她她她她她\n",
      "[48, 48, 48, 48, 48, 48, 48, 48, 48]\n",
      "紧张紧张紧张紧张紧张紧张紧张紧张紧张\n",
      "[196, 196, 196, 197, 138, 138, 138, 32, 160]\n",
      "礼貌礼貌礼貌祖母尺子尺子尺子团结推荐\n",
      "[212, 212, 212, 26, 26, 26, 26, 26, 26]\n",
      "褐色褐色褐色爸爸爸爸爸爸爸爸爸爸爸爸\n",
      "[220, 51, 51, 51, 51, 51, 51, 51, 51]\n",
      "门卫邻居邻居邻居邻居邻居邻居邻居邻居\n",
      "[94, 94, 94, 20, 20, 20, 20, 20, 20]\n",
      "丰富丰富丰富基础基础基础基础基础基础\n",
      "[204, 167, 14, 14, 14, 14, 14, 14, 14]\n",
      "美容星星工作工作工作工作工作工作工作\n",
      "[27, 27, 27, 27, 27, 27, 27, 129, 160]\n",
      "目标目标目标目标目标目标目标姐夫推荐\n",
      "[139, 139, 139, 139, 139, 139, 15, 15, 15]\n",
      "局势局势局势局势局势局势哥哥哥哥哥哥\n",
      "[124, 124, 124, 124, 124, 124, 124, 124, 124]\n",
      "天气预报天气预报天气预报天气预报天气预报天气预报天气预报天气预报天气预报\n",
      "[191, 148, 148, 148, 148, 148, 177, 121, 61]\n",
      "疏形成形成形成形成形成气氛圆满成功17\n",
      "[108, 108, 108, 42, 42, 42, 42, 42, 42]\n",
      "刑警刑警刑警情况情况情况情况情况情况\n",
      "[29, 29, 29, 29, 29, 29, 29, 29, 29]\n",
      "稳定稳定稳定稳定稳定稳定稳定稳定稳定\n",
      "[102, 102, 102, 102, 132, 26, 26, 26, 26]\n",
      "保卫保卫保卫保卫学生爸爸爸爸爸爸爸爸\n",
      "[38, 38, 38, 38, 38, 38, 38, 38, 38]\n",
      "婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆\n",
      "[8, 8, 8, 8, 8, 8, 8, 8, 8]\n",
      "你你你你你你你你你\n",
      "[14, 14, 14, 14, 14, 14, 14, 14, 14]\n",
      "工作工作工作工作工作工作工作工作工作\n",
      "[189, 150, 150, 161, 161, 161, 161, 161, 161]\n",
      "电池恒星恒星搞清搞清搞清搞清搞清搞清\n",
      "[85, 36, 36, 36, 36, 36, 36, 36, 36]\n",
      "39她她她她她她她她\n",
      "[147, 147, 173, 14, 14, 14, 14, 14, 14]\n",
      "弱智人弱智人橙色工作工作工作工作工作工作\n",
      "[41, 41, 41, 41, 41, 41, 41, 41, 41]\n",
      "形势形势形势形势形势形势形势形势形势\n",
      "[126, 126, 126, 126, 126, 126, 126, 126, 126]\n",
      "太阳太阳太阳太阳太阳太阳太阳太阳太阳\n",
      "[157, 157, 157, 157, 157, 157, 157, 157, 157]\n",
      "招聘招聘招聘招聘招聘招聘招聘招聘招聘\n",
      "[213, 213, 213, 213, 213, 213, 213, 213, 213]\n",
      "观察观察观察观察观察观察观察观察观察\n",
      "[37, 37, 37, 37, 37, 37, 37, 76, 205]\n",
      "好好好好好好好30聋人\n",
      "[144, 144, 144, 144, 144, 144, 144, 144, 144]\n",
      "平等平等平等平等平等平等平等平等平等\n",
      "[88, 45, 45, 45, 45, 45, 45, 45, 45]\n",
      "41残疾人残疾人残疾人残疾人残疾人残疾人残疾人残疾人\n",
      "[188, 188, 188, 188, 188, 188, 188, 188, 188]\n",
      "现实情况现实情况现实情况现实情况现实情况现实情况现实情况现实情况现实情况\n",
      "[79, 160, 49, 49, 49, 49, 49, 49, 49]\n",
      "33推荐裁缝裁缝裁缝裁缝裁缝裁缝裁缝\n",
      "[41, 41, 41, 41, 41, 41, 41, 41, 41]\n",
      "形势形势形势形势形势形势形势形势形势\n",
      "[134, 134, 134, 222, 222, 222, 222, 222, 222]\n",
      "容易容易容易颜色颜色颜色颜色颜色颜色\n",
      "[56, 139, 139, 30, 30, 30, 30, 30, 30]\n",
      "12局势局势儿子儿子儿子儿子儿子儿子\n",
      "[10, 10, 10, 10, 10, 222, 222, 45, 45]\n",
      "同学同学同学同学同学颜色颜色残疾人残疾人\n",
      "[13, 13, 13, 13, 13, 13, 13, 13, 13]\n",
      "国家国家国家国家国家国家国家国家国家\n",
      "[82, 194, 113, 41, 99, 99, 153, 140, 140]\n",
      "36知识分子卫星形势任务任务手表岗位岗位\n",
      "[137, 137, 137, 137, 137, 137, 137, 42, 42]\n",
      "小孩子小孩子小孩子小孩子小孩子小孩子小孩子情况情况\n",
      "[32, 32, 32, 32, 32, 32, 32, 32, 32]\n",
      "团结团结团结团结团结团结团结团结团结\n",
      "[187, 187, 187, 187, 187, 187, 187, 187, 187]\n",
      "现实现实现实现实现实现实现实现实现实\n",
      "[171, 171, 171, 171, 171, 171, 171, 171, 171]\n",
      "杯子杯子杯子杯子杯子杯子杯子杯子杯子\n",
      "[24, 24, 24, 24, 24, 24, 24, 24, 51]\n",
      "新新新新新新新新邻居\n",
      "[111, 111, 111, 111, 111, 94, 104, 78, 38]\n",
      "加强加强加强加强加强丰富保安32婆婆\n",
      "[198, 84, 149, 149, 149, 149, 149, 149, 149]\n",
      "空38律师律师律师律师律师律师律师\n",
      "[162, 162, 116, 116, 116, 116, 116, 119, 119]\n",
      "摆脱摆脱发挥发挥发挥发挥发挥园丁园丁\n",
      "[85, 38, 38, 38, 38, 38, 38, 38, 38]\n",
      "39婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆\n",
      "[102, 102, 102, 102, 9, 9, 9, 9, 9]\n",
      "保卫保卫保卫保卫我们我们我们我们我们\n",
      "[81, 121, 121, 121, 121, 121, 121, 121, 121]\n",
      "35圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功\n",
      "[163, 163, 114, 114, 149, 149, 149, 149, 149]\n",
      "放弃放弃去去律师律师律师律师律师\n",
      "[135, 135, 90, 183, 183, 84, 18, 18, 18]\n",
      "富强富强6牙刷牙刷38丈夫丈夫丈夫\n",
      "[59, 84, 96, 96, 96, 96, 96, 96, 96]\n",
      "1538事情事情事情事情事情事情事情\n",
      "[7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "我我我我我我我我我\n",
      "[201, 201, 201, 201, 201, 201, 201, 201, 201]\n",
      "结果结果结果结果结果结果结果结果结果\n",
      "[16, 16, 16, 16, 16, 16, 16, 16, 16]\n",
      "外祖父外祖父外祖父外祖父外祖父外祖父外祖父外祖父外祖父\n",
      "[32, 32, 32, 32, 32, 32, 32, 32, 32]\n",
      "团结团结团结团结团结团结团结团结团结\n",
      "[198, 222, 222, 222, 178, 192, 192, 192, 192]\n",
      "空颜色颜色颜色没有盆盆盆盆\n",
      "[25, 25, 25, 25, 25, 25, 25, 25, 25]\n",
      "朋友朋友朋友朋友朋友朋友朋友朋友朋友\n",
      "[31, 31, 31, 31, 31, 31, 31, 31, 31]\n",
      "公公公公公公公公公公公公公公公公公公\n",
      "[121, 121, 121, 121, 121, 121, 121, 121, 121]\n",
      "圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功\n",
      "[181, 157, 157, 97, 97, 97, 97, 97, 18]\n",
      "演员招聘招聘他人他人他人他人他人丈夫\n",
      "[32, 32, 32, 32, 32, 32, 32, 32, 32]\n",
      "团结团结团结团结团结团结团结团结团结\n",
      "[187, 187, 187, 187, 187, 187, 187, 187, 187]\n",
      "现实现实现实现实现实现实现实现实现实\n",
      "[8, 8, 8, 8, 8, 8, 8, 8, 8]\n",
      "你你你你你你你你你\n",
      "[124, 124, 124, 124, 124, 124, 124, 124, 124]\n",
      "天气预报天气预报天气预报天气预报天气预报天气预报天气预报天气预报天气预报\n",
      "[171, 171, 171, 171, 171, 171, 171, 171, 171]\n",
      "杯子杯子杯子杯子杯子杯子杯子杯子杯子\n",
      "[8, 8, 8, 8, 8, 8, 8, 8, 8]\n",
      "你你你你你你你你你\n",
      "[38, 38, 38, 38, 38, 38, 38, 38, 38]\n",
      "婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆\n",
      "[41, 41, 41, 41, 41, 41, 41, 41, 41]\n",
      "形势形势形势形势形势形势形势形势形势\n",
      "[152, 152, 152, 152, 152, 152, 152, 152, 152]\n",
      "手电筒手电筒手电筒手电筒手电筒手电筒手电筒手电筒手电筒\n",
      "[8, 8, 8, 8, 8, 8, 8, 8, 8]\n",
      "你你你你你你你你你\n",
      "[156, 156, 156, 3, 3, 3, 3, 3, 3]\n",
      "招呼招呼招呼<end><end><end><end><end><end>\n",
      "[16, 16, 16, 16, 16, 16, 16, 16, 16]\n",
      "外祖父外祖父外祖父外祖父外祖父外祖父外祖父外祖父外祖父\n",
      "[120, 120, 120, 120, 120, 120, 120, 120, 120]\n",
      "国民国民国民国民国民国民国民国民国民\n",
      "[152, 152, 152, 152, 152, 152, 152, 152, 152]\n",
      "手电筒手电筒手电筒手电筒手电筒手电筒手电筒手电筒手电筒\n",
      "[111, 111, 111, 111, 111, 111, 111, 111, 111]\n",
      "加强加强加强加强加强加强加强加强加强\n",
      "[187, 187, 187, 187, 187, 187, 187, 187, 170]\n",
      "现实现实现实现实现实现实现实现实来\n",
      "[13, 13, 13, 13, 13, 13, 13, 13, 13]\n",
      "国家国家国家国家国家国家国家国家国家\n",
      "[16, 16, 16, 16, 16, 16, 16, 16, 16]\n",
      "外祖父外祖父外祖父外祖父外祖父外祖父外祖父外祖父外祖父\n",
      "[124, 124, 124, 124, 8, 8, 8, 8, 8]\n",
      "天气预报天气预报天气预报天气预报你你你你你\n",
      "[188, 188, 188, 188, 188, 188, 188, 188, 188]\n",
      "现实情况现实情况现实情况现实情况现实情况现实情况现实情况现实情况现实情况\n",
      "[197, 197, 197, 110, 110, 110, 110, 110, 110]\n",
      "祖母祖母祖母剪刀剪刀剪刀剪刀剪刀剪刀\n",
      "[156, 156, 156, 17, 17, 17, 17, 17, 17]\n",
      "招呼招呼招呼妈妈妈妈妈妈妈妈妈妈妈妈\n",
      "[157, 157, 157, 157, 157, 157, 157, 157, 157]\n",
      "招聘招聘招聘招聘招聘招聘招聘招聘招聘\n",
      "[222, 222, 222, 222, 222, 222, 222, 222, 222]\n",
      "颜色颜色颜色颜色颜色颜色颜色颜色颜色\n",
      "[187, 187, 187, 187, 187, 187, 187, 187, 187]\n",
      "现实现实现实现实现实现实现实现实现实\n",
      "[23, 23, 23, 23, 23, 23, 23, 23, 23]\n",
      "提高提高提高提高提高提高提高提高提高\n",
      "[171, 171, 171, 171, 171, 171, 171, 171, 171]\n",
      "杯子杯子杯子杯子杯子杯子杯子杯子杯子\n",
      "[31, 31, 31, 31, 31, 31, 31, 31, 31]\n",
      "公公公公公公公公公公公公公公公公公公\n",
      "[23, 23, 23, 23, 23, 23, 23, 23, 23]\n",
      "提高提高提高提高提高提高提高提高提高\n",
      "[43, 43, 43, 43, 43, 43, 43, 173, 177]\n",
      "护士护士护士护士护士护士护士橙色气氛\n",
      "[152, 152, 152, 152, 152, 152, 152, 152, 152]\n",
      "手电筒手电筒手电筒手电筒手电筒手电筒手电筒手电筒手电筒\n",
      "[29, 29, 29, 29, 29, 29, 29, 29, 29]\n",
      "稳定稳定稳定稳定稳定稳定稳定稳定稳定\n",
      "[51, 51, 51, 51, 51, 51, 190, 199, 199]\n",
      "邻居邻居邻居邻居邻居邻居画家经济经济\n",
      "[121, 121, 121, 121, 121, 121, 121, 121, 121]\n",
      "圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功\n",
      "[51, 51, 51, 51, 51, 51, 51, 51, 51]\n",
      "邻居邻居邻居邻居邻居邻居邻居邻居邻居\n",
      "[150, 150, 150, 150, 5, 5, 5, 5, 5]\n",
      "恒星恒星恒星恒星是是是是是\n",
      "[192, 192, 192, 192, 192, 192, 192, 192, 192]\n",
      "盆盆盆盆盆盆盆盆盆\n",
      "[222, 222, 222, 222, 222, 222, 222, 222, 222]\n",
      "颜色颜色颜色颜色颜色颜色颜色颜色颜色\n",
      "[150, 150, 150, 17, 17, 17, 17, 17, 17]\n",
      "恒星恒星恒星妈妈妈妈妈妈妈妈妈妈妈妈\n",
      "[208, 208, 208, 208, 208, 208, 208, 208, 208]\n",
      "茶壶茶壶茶壶茶壶茶壶茶壶茶壶茶壶茶壶\n",
      "[164, 164, 164, 164, 164, 164, 164, 164, 164]\n",
      "效益效益效益效益效益效益效益效益效益\n",
      "[32, 32, 32, 32, 32, 32, 32, 32, 32]\n",
      "团结团结团结团结团结团结团结团结团结\n",
      "[148, 148, 148, 148, 148, 148, 148, 148, 148]\n",
      "形成形成形成形成形成形成形成形成形成\n",
      "[213, 213, 213, 213, 213, 213, 213, 213, 213]\n",
      "观察观察观察观察观察观察观察观察观察\n",
      "[126, 126, 126, 126, 126, 126, 126, 126, 126]\n",
      "太阳太阳太阳太阳太阳太阳太阳太阳太阳\n",
      "[21, 21, 21, 21, 21, 21, 21, 21, 21]\n",
      "妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹\n",
      "[92, 205, 130, 130, 130, 130, 130, 130, 130]\n",
      "8聋人姐姐姐姐姐姐姐姐姐姐姐姐姐姐\n",
      "[148, 148, 148, 148, 148, 148, 148, 148, 148]\n",
      "形成形成形成形成形成形成形成形成形成\n",
      "[148, 148, 148, 148, 148, 148, 148, 59, 11]\n",
      "形成形成形成形成形成形成形成15有\n",
      "[6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "他他他他他他他他他\n",
      "[7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "我我我我我我我我我\n",
      "[152, 152, 152, 152, 8, 8, 8, 8, 8]\n",
      "手电筒手电筒手电筒手电筒你你你你你\n",
      "[41, 41, 41, 41, 41, 41, 41, 41, 41]\n",
      "形势形势形势形势形势形势形势形势形势\n",
      "[172, 103, 202, 41, 124, 124, 124, 176, 176]\n",
      "模特保姆绿形势天气预报天气预报天气预报毛巾毛巾\n",
      "[19, 19, 19, 19, 19, 19, 19, 19, 19]\n",
      "地位地位地位地位地位地位地位地位地位\n",
      "[212, 212, 212, 6, 6, 6, 6, 6, 6]\n",
      "褐色褐色褐色他他他他他他\n",
      "[148, 148, 148, 148, 148, 148, 148, 148, 148]\n",
      "形成形成形成形成形成形成形成形成形成\n",
      "[4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "的的的的的的的的的\n",
      "[162, 162, 88, 115, 20, 20, 20, 20, 20]\n",
      "摆脱摆脱41友谊基础基础基础基础基础\n",
      "[47, 47, 47, 47, 47, 47, 47, 47, 47]\n",
      "民主民主民主民主民主民主民主民主民主\n",
      "[171, 171, 171, 171, 171, 171, 171, 171, 171]\n",
      "杯子杯子杯子杯子杯子杯子杯子杯子杯子\n",
      "[7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "我我我我我我我我我\n",
      "[36, 36, 36, 36, 36, 36, 36, 36, 36]\n",
      "她她她她她她她她她\n",
      "[116, 116, 116, 116, 116, 116, 116, 116, 116]\n",
      "发挥发挥发挥发挥发挥发挥发挥发挥发挥\n",
      "[41, 41, 41, 41, 41, 41, 41, 41, 41]\n",
      "形势形势形势形势形势形势形势形势形势\n",
      "[16, 16, 16, 16, 16, 16, 16, 16, 16]\n",
      "外祖父外祖父外祖父外祖父外祖父外祖父外祖父外祖父外祖父\n",
      "[148, 148, 148, 148, 148, 148, 148, 148, 148]\n",
      "形成形成形成形成形成形成形成形成形成\n",
      "[194, 180, 123, 5, 5, 5, 5, 5, 5]\n",
      "知识分子深外祖母是是是是是是\n",
      "[41, 41, 41, 41, 41, 41, 41, 41, 41]\n",
      "形势形势形势形势形势形势形势形势形势\n",
      "[148, 148, 148, 148, 171, 171, 171, 171, 171]\n",
      "形成形成形成形成杯子杯子杯子杯子杯子\n",
      "[213, 213, 213, 213, 213, 213, 213, 213, 213]\n",
      "观察观察观察观察观察观察观察观察观察\n",
      "[41, 41, 41, 41, 41, 41, 41, 41, 41]\n",
      "形势形势形势形势形势形势形势形势形势\n",
      "[80, 13, 13, 13, 13, 13, 13, 13, 194]\n",
      "34国家国家国家国家国家国家国家知识分子\n",
      "[219, 163, 163, 194, 194, 194, 45, 45, 143]\n",
      "锋利放弃放弃知识分子知识分子知识分子残疾人残疾人干\n",
      "[72, 117, 117, 117, 137, 137, 137, 137, 6]\n",
      "27向导向导向导小孩子小孩子小孩子小孩子他\n",
      "[58, 222, 222, 222, 222, 222, 222, 222, 222]\n",
      "14颜色颜色颜色颜色颜色颜色颜色颜色\n",
      "[132, 199, 199, 199, 199, 199, 199, 221, 221]\n",
      "学生经济经济经济经济经济经济项链项链\n",
      "[21, 21, 21, 21, 21, 21, 21, 21, 21]\n",
      "妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹\n",
      "[144, 153, 188, 188, 188, 188, 11, 11, 11]\n",
      "平等手表现实情况现实情况现实情况现实情况有有有\n",
      "[124, 124, 124, 124, 124, 124, 124, 124, 124]\n",
      "天气预报天气预报天气预报天气预报天气预报天气预报天气预报天气预报天气预报\n",
      "[137, 137, 137, 137, 137, 137, 137, 137, 137]\n",
      "小孩子小孩子小孩子小孩子小孩子小孩子小孩子小孩子小孩子\n",
      "[171, 171, 171, 171, 171, 171, 171, 171, 171]\n",
      "杯子杯子杯子杯子杯子杯子杯子杯子杯子\n",
      "[124, 124, 124, 124, 124, 124, 124, 117, 215]\n",
      "天气预报天气预报天气预报天气预报天气预报天气预报天气预报向导记者\n",
      "[171, 171, 171, 171, 171, 171, 171, 171, 171]\n",
      "杯子杯子杯子杯子杯子杯子杯子杯子杯子\n",
      "[219, 219, 219, 215, 215, 215, 215, 150, 34]\n",
      "锋利锋利锋利记者记者记者记者恒星地球\n",
      "[17, 17, 17, 17, 17, 17, 17, 17, 17]\n",
      "妈妈妈妈妈妈妈妈妈妈妈妈妈妈妈妈妈妈\n",
      "[4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "的的的的的的的的的\n",
      "[106, 188, 188, 188, 188, 188, 188, 188, 188]\n",
      "公务员现实情况现实情况现实情况现实情况现实情况现实情况现实情况现实情况\n",
      "[41, 41, 41, 41, 41, 41, 41, 41, 41]\n",
      "形势形势形势形势形势形势形势形势形势\n",
      "[201, 201, 201, 201, 201, 201, 201, 201, 201]\n",
      "结果结果结果结果结果结果结果结果结果\n",
      "[4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "的的的的的的的的的\n",
      "[41, 41, 41, 41, 41, 41, 41, 41, 41]\n",
      "形势形势形势形势形势形势形势形势形势\n",
      "[174, 174, 174, 174, 14, 14, 14, 14, 14]\n",
      "武警武警武警武警工作工作工作工作工作\n",
      "[127, 127, 127, 127, 127, 182, 182, 182, 182]\n",
      "女朋友女朋友女朋友女朋友女朋友炊事员炊事员炊事员炊事员\n",
      "[48, 48, 48, 48, 48, 48, 48, 48, 48]\n",
      "紧张紧张紧张紧张紧张紧张紧张紧张紧张\n",
      "[45, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "残疾人他他他他他他他他\n",
      "[187, 187, 187, 187, 187, 187, 187, 187, 187]\n",
      "现实现实现实现实现实现实现实现实现实\n",
      "[156, 156, 156, 156, 156, 156, 156, 20, 20]\n",
      "招呼招呼招呼招呼招呼招呼招呼基础基础\n",
      "[146, 146, 146, 146, 146, 146, 146, 146, 146]\n",
      "弟弟弟弟弟弟弟弟弟弟弟弟弟弟弟弟弟弟\n",
      "[171, 171, 171, 171, 171, 171, 171, 171, 171]\n",
      "杯子杯子杯子杯子杯子杯子杯子杯子杯子\n",
      "[200, 200, 125, 125, 125, 125, 125, 125, 125]\n",
      "经验丰富经验丰富天空天空天空天空天空天空天空\n",
      "[4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "的的的的的的的的的\n",
      "[38, 38, 38, 38, 38, 38, 38, 38, 38]\n",
      "婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆\n",
      "[158, 158, 179, 179, 179, 179, 179, 179, 179]\n",
      "拜访拜访洗脸盆洗脸盆洗脸盆洗脸盆洗脸盆洗脸盆洗脸盆\n",
      "[137, 217, 217, 217, 217, 217, 137, 137, 137]\n",
      "小孩子邮递员邮递员邮递员邮递员邮递员小孩子小孩子小孩子\n",
      "[162, 162, 162, 63, 56, 124, 124, 161, 161]\n",
      "摆脱摆脱摆脱1912天气预报天气预报搞清搞清\n",
      "[55, 41, 41, 160, 160, 201, 201, 201, 201]\n",
      "11形势形势推荐推荐结果结果结果结果\n",
      "[21, 21, 21, 21, 21, 21, 21, 21, 21]\n",
      "妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹\n",
      "[162, 46, 46, 46, 46, 46, 46, 46, 46]\n",
      "摆脱毛毯毛毯毛毯毛毯毛毯毛毯毛毯毛毯\n",
      "[188, 188, 188, 188, 188, 188, 188, 188, 188]\n",
      "现实情况现实情况现实情况现实情况现实情况现实情况现实情况现实情况现实情况\n",
      "[145, 145, 145, 145, 145, 145, 145, 145, 145]\n",
      "引导引导引导引导引导引导引导引导引导\n",
      "[16, 16, 16, 16, 16, 16, 16, 16, 16]\n",
      "外祖父外祖父外祖父外祖父外祖父外祖父外祖父外祖父外祖父\n",
      "[121, 121, 121, 121, 121, 121, 121, 121, 121]\n",
      "圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功\n",
      "[187, 187, 187, 187, 187, 187, 187, 187, 187]\n",
      "现实现实现实现实现实现实现实现实现实\n",
      "[215, 215, 215, 215, 215, 215, 215, 215, 201]\n",
      "记者记者记者记者记者记者记者记者结果\n",
      "[23, 23, 23, 23, 23, 23, 23, 23, 23]\n",
      "提高提高提高提高提高提高提高提高提高\n",
      "[187, 187, 187, 187, 121, 121, 121, 121, 121]\n",
      "现实现实现实现实圆满成功圆满成功圆满成功圆满成功圆满成功\n",
      "[151, 150, 150, 150, 156, 167, 132, 132, 140]\n",
      "成功恒星恒星恒星招呼星星学生学生岗位\n",
      "[124, 124, 124, 124, 124, 124, 124, 124, 124]\n",
      "天气预报天气预报天气预报天气预报天气预报天气预报天气预报天气预报天气预报\n",
      "[60, 176, 176, 166, 50, 50, 214, 11, 11]\n",
      "16毛巾毛巾教练警察警察解放军有有\n",
      "[21, 21, 21, 21, 21, 21, 21, 21, 21]\n",
      "妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹\n",
      "[171, 171, 171, 171, 171, 171, 171, 171, 171]\n",
      "杯子杯子杯子杯子杯子杯子杯子杯子杯子\n",
      "[85, 179, 179, 179, 179, 208, 208, 208, 208]\n",
      "39洗脸盆洗脸盆洗脸盆洗脸盆茶壶茶壶茶壶茶壶\n",
      "[137, 137, 137, 137, 137, 137, 137, 137, 137]\n",
      "小孩子小孩子小孩子小孩子小孩子小孩子小孩子小孩子小孩子\n",
      "[124, 124, 124, 124, 124, 124, 124, 124, 124]\n",
      "天气预报天气预报天气预报天气预报天气预报天气预报天气预报天气预报天气预报\n",
      "[125, 125, 125, 125, 125, 125, 125, 163, 163]\n",
      "天空天空天空天空天空天空天空放弃放弃\n",
      "[121, 121, 121, 121, 121, 121, 121, 121, 121]\n",
      "圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功\n",
      "[162, 162, 152, 152, 152, 152, 152, 152, 152]\n",
      "摆脱摆脱手电筒手电筒手电筒手电筒手电筒手电筒手电筒\n",
      "[16, 16, 16, 16, 16, 16, 16, 16, 16]\n",
      "外祖父外祖父外祖父外祖父外祖父外祖父外祖父外祖父外祖父\n",
      "[198, 198, 198, 85, 135, 114, 5, 5, 5]\n",
      "空空空39富强去是是是\n",
      "[56, 95, 95, 95, 175, 175, 175, 155, 86]\n",
      "12事业成功事业成功事业成功歪歪歪扭转局面4\n",
      "[171, 171, 171, 171, 171, 171, 171, 171, 171]\n",
      "杯子杯子杯子杯子杯子杯子杯子杯子杯子\n",
      "[178, 178, 124, 124, 124, 124, 124, 124, 124]\n",
      "没有没有天气预报天气预报天气预报天气预报天气预报天气预报天气预报\n",
      "[47, 47, 47, 47, 47, 47, 47, 47, 47]\n",
      "民主民主民主民主民主民主民主民主民主\n",
      "[204, 126, 126, 126, 126, 126, 41, 41, 41]\n",
      "美容太阳太阳太阳太阳太阳形势形势形势\n",
      "[160, 28, 28, 28, 28, 28, 28, 28, 28]\n",
      "推荐祖父祖父祖父祖父祖父祖父祖父祖父\n",
      "[16, 16, 16, 16, 16, 16, 16, 16, 16]\n",
      "外祖父外祖父外祖父外祖父外祖父外祖父外祖父外祖父外祖父\n",
      "[121, 121, 121, 121, 121, 121, 121, 121, 121]\n",
      "圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功\n",
      "[221, 221, 4, 4, 4, 4, 4, 4, 4]\n",
      "项链项链的的的的的的的\n",
      "[220, 147, 147, 55, 104, 26, 26, 26, 42]\n",
      "门卫弱智人弱智人11保安爸爸爸爸爸爸情况\n",
      "[138, 138, 138, 138, 138, 138, 138, 138, 138]\n",
      "尺子尺子尺子尺子尺子尺子尺子尺子尺子\n",
      "[181, 183, 183, 135, 135, 33, 95, 164, 164]\n",
      "演员牙刷牙刷富强富强困难事业成功效益效益\n",
      "[194, 194, 194, 157, 157, 157, 157, 157, 157]\n",
      "知识分子知识分子知识分子招聘招聘招聘招聘招聘招聘\n",
      "[171, 171, 171, 171, 171, 171, 171, 171, 171]\n",
      "杯子杯子杯子杯子杯子杯子杯子杯子杯子\n",
      "[189, 161, 161, 161, 161, 161, 161, 161, 161]\n",
      "电池搞清搞清搞清搞清搞清搞清搞清搞清\n",
      "[70, 183, 183, 179, 202, 202, 4, 4, 4]\n",
      "25牙刷牙刷洗脸盆绿绿的的的\n",
      "[135, 135, 168, 168, 168, 168, 168, 168, 168]\n",
      "富强富强月亮月亮月亮月亮月亮月亮月亮\n",
      "[7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "我我我我我我我我我\n",
      "[57, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "13的的的的的的的的\n",
      "[128, 128, 128, 128, 132, 132, 31, 31, 31]\n",
      "妻子妻子妻子妻子学生学生公公公公公公\n",
      "[171, 38, 17, 17, 17, 17, 17, 17, 17]\n",
      "杯子婆婆妈妈妈妈妈妈妈妈妈妈妈妈妈妈\n",
      "[81, 134, 114, 143, 47, 195, 195, 149, 55]\n",
      "35容易去干民主破破律师11\n",
      "[116, 116, 116, 116, 116, 116, 116, 116, 116]\n",
      "发挥发挥发挥发挥发挥发挥发挥发挥发挥\n",
      "[150, 150, 150, 150, 114, 104, 84, 175, 167]\n",
      "恒星恒星恒星恒星去保安38歪星星\n",
      "[45, 45, 151, 56, 155, 155, 155, 155, 155]\n",
      "残疾人残疾人成功12扭转局面扭转局面扭转局面扭转局面扭转局面\n",
      "[116, 116, 116, 116, 116, 116, 116, 116, 116]\n",
      "发挥发挥发挥发挥发挥发挥发挥发挥发挥\n",
      "[7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "我我我我我我我我我\n",
      "[10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "同学同学同学同学同学同学同学同学同学\n",
      "[179, 179, 179, 179, 179, 179, 179, 179, 179]\n",
      "洗脸盆洗脸盆洗脸盆洗脸盆洗脸盆洗脸盆洗脸盆洗脸盆洗脸盆\n",
      "[7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "我我我我我我我我我\n",
      "[171, 171, 171, 171, 171, 171, 171, 171, 171]\n",
      "杯子杯子杯子杯子杯子杯子杯子杯子杯子\n",
      "[98, 98, 98, 98, 98, 98, 98, 98, 98]\n",
      "他们他们他们他们他们他们他们他们他们\n",
      "[154, 73, 176, 176, 211, 211, 3, 3, 3]\n",
      "打火机28毛巾毛巾被子被子<end><end><end>\n",
      "[23, 23, 23, 23, 23, 23, 23, 23, 23]\n",
      "提高提高提高提高提高提高提高提高提高\n",
      "[40, 40, 40, 40, 40, 40, 40, 40, 40]\n",
      "就业就业就业就业就业就业就业就业就业\n",
      "[207, 2, 35, 35, 35, 35, 36, 36, 36]\n",
      "自由恋爱<unk>多多多多她她她\n",
      "[29, 29, 29, 29, 29, 29, 29, 29, 29]\n",
      "稳定稳定稳定稳定稳定稳定稳定稳定稳定\n",
      "[194, 194, 194, 194, 112, 112, 42, 42, 42]\n",
      "知识分子知识分子知识分子知识分子医生医生情况情况情况\n",
      "[121, 121, 121, 121, 121, 121, 121, 121, 121]\n",
      "圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功\n",
      "[192, 192, 192, 192, 192, 192, 192, 192, 192]\n",
      "盆盆盆盆盆盆盆盆盆\n",
      "[21, 21, 21, 21, 21, 21, 21, 21, 21]\n",
      "妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹\n",
      "[221, 221, 51, 51, 51, 51, 51, 51, 51]\n",
      "项链项链邻居邻居邻居邻居邻居邻居邻居\n",
      "[55, 219, 219, 121, 162, 162, 162, 162, 70]\n",
      "11锋利锋利圆满成功摆脱摆脱摆脱摆脱25\n",
      "[201, 201, 179, 179, 179, 179, 179, 179, 179]\n",
      "结果结果洗脸盆洗脸盆洗脸盆洗脸盆洗脸盆洗脸盆洗脸盆\n",
      "[157, 157, 157, 157, 157, 157, 157, 157, 157]\n",
      "招聘招聘招聘招聘招聘招聘招聘招聘招聘\n",
      "[200, 200, 200, 145, 145, 145, 145, 145, 145]\n",
      "经验丰富经验丰富经验丰富引导引导引导引导引导引导\n",
      "[130, 130, 130, 130, 130, 130, 52, 27, 27]\n",
      "姐姐姐姐姐姐姐姐姐姐姐姐0目标目标\n",
      "[179, 179, 179, 179, 179, 179, 179, 179, 179]\n",
      "洗脸盆洗脸盆洗脸盆洗脸盆洗脸盆洗脸盆洗脸盆洗脸盆洗脸盆\n",
      "[4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "的的的的的的的的的\n",
      "[161, 161, 161, 161, 161, 161, 161, 161, 161]\n",
      "搞清搞清搞清搞清搞清搞清搞清搞清搞清\n",
      "[48, 48, 48, 48, 48, 48, 48, 48, 48]\n",
      "紧张紧张紧张紧张紧张紧张紧张紧张紧张\n",
      "[171, 171, 171, 171, 171, 171, 171, 171, 171]\n",
      "杯子杯子杯子杯子杯子杯子杯子杯子杯子\n",
      "[121, 121, 121, 121, 121, 121, 177, 177, 220]\n",
      "圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功气氛气氛门卫\n",
      "[7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "我我我我我我我我我\n",
      "[16, 16, 16, 16, 16, 16, 16, 16, 16]\n",
      "外祖父外祖父外祖父外祖父外祖父外祖父外祖父外祖父外祖父\n",
      "[148, 148, 148, 148, 148, 171, 171, 171, 171]\n",
      "形成形成形成形成形成杯子杯子杯子杯子\n",
      "[170, 170, 94, 94, 161, 161, 161, 161, 161]\n",
      "来来丰富丰富搞清搞清搞清搞清搞清\n",
      "[87, 95, 123, 123, 123, 123, 2, 81, 11]\n",
      "40事业成功外祖母外祖母外祖母外祖母<unk>35有\n",
      "[162, 134, 216, 146, 200, 200, 200, 200, 123]\n",
      "摆脱容易贫苦弟弟经验丰富经验丰富经验丰富经验丰富外祖母\n",
      "[111, 111, 111, 111, 111, 111, 111, 111, 111]\n",
      "加强加强加强加强加强加强加强加强加强\n",
      "[124, 124, 124, 124, 124, 124, 124, 124, 124]\n",
      "天气预报天气预报天气预报天气预报天气预报天气预报天气预报天气预报天气预报\n",
      "[130, 130, 130, 130, 130, 130, 130, 130, 130]\n",
      "姐姐姐姐姐姐姐姐姐姐姐姐姐姐姐姐姐姐\n",
      "[187, 187, 187, 187, 187, 187, 187, 187, 187]\n",
      "现实现实现实现实现实现实现实现实现实\n",
      "[41, 43, 43, 43, 43, 43, 43, 43, 43]\n",
      "形势护士护士护士护士护士护士护士护士\n",
      "[4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "的的的的的的的的的\n",
      "[24, 24, 24, 24, 24, 24, 24, 24, 24]\n",
      "新新新新新新新新新\n",
      "[188, 188, 188, 188, 188, 188, 188, 188, 188]\n",
      "现实情况现实情况现实情况现实情况现实情况现实情况现实情况现实情况现实情况\n",
      "[187, 187, 187, 187, 187, 187, 187, 187, 187]\n",
      "现实现实现实现实现实现实现实现实现实\n",
      "[42, 42, 23, 23, 23, 23, 23, 23, 23]\n",
      "情况情况提高提高提高提高提高提高提高\n",
      "[126, 126, 126, 126, 126, 126, 126, 126, 126]\n",
      "太阳太阳太阳太阳太阳太阳太阳太阳太阳\n",
      "[79, 40, 40, 40, 40, 40, 40, 40, 31]\n",
      "33就业就业就业就业就业就业就业公公\n",
      "[38, 145, 164, 164, 164, 164, 164, 164, 164]\n",
      "婆婆引导效益效益效益效益效益效益效益\n",
      "[41, 41, 41, 41, 41, 41, 41, 41, 67]\n",
      "形势形势形势形势形势形势形势形势22\n",
      "[125, 125, 125, 125, 125, 125, 125, 125, 125]\n",
      "天空天空天空天空天空天空天空天空天空\n",
      "[201, 201, 201, 201, 201, 201, 201, 201, 201]\n",
      "结果结果结果结果结果结果结果结果结果\n",
      "[187, 187, 187, 187, 187, 187, 187, 187, 187]\n",
      "现实现实现实现实现实现实现实现实现实\n",
      "[91, 167, 167, 195, 167, 20, 20, 20, 20]\n",
      "7星星星星破星星基础基础基础基础\n",
      "[187, 187, 187, 187, 187, 187, 187, 187, 187]\n",
      "现实现实现实现实现实现实现实现实现实\n",
      "[134, 141, 27, 27, 27, 27, 27, 27, 27]\n",
      "容易岳父目标目标目标目标目标目标目标\n",
      "[124, 124, 124, 124, 124, 124, 124, 124, 124]\n",
      "天气预报天气预报天气预报天气预报天气预报天气预报天气预报天气预报天气预报\n",
      "[9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "我们我们我们我们我们我们我们我们我们\n",
      "[188, 188, 188, 188, 188, 188, 188, 188, 188]\n",
      "现实情况现实情况现实情况现实情况现实情况现实情况现实情况现实情况现实情况\n",
      "[4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "的的的的的的的的的\n",
      "[196, 110, 167, 167, 167, 167, 48, 48, 167]\n",
      "礼貌剪刀星星星星星星星星紧张紧张星星\n",
      "[38, 38, 38, 38, 38, 38, 38, 38, 38]\n",
      "婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆\n",
      "[152, 152, 152, 152, 152, 152, 152, 152, 152]\n",
      "手电筒手电筒手电筒手电筒手电筒手电筒手电筒手电筒手电筒\n",
      "[16, 16, 16, 16, 16, 16, 16, 16, 16]\n",
      "外祖父外祖父外祖父外祖父外祖父外祖父外祖父外祖父外祖父\n",
      "[179, 179, 179, 179, 179, 179, 179, 179, 179]\n",
      "洗脸盆洗脸盆洗脸盆洗脸盆洗脸盆洗脸盆洗脸盆洗脸盆洗脸盆\n",
      "[157, 157, 157, 157, 157, 157, 157, 157, 157]\n",
      "招聘招聘招聘招聘招聘招聘招聘招聘招聘\n",
      "[184, 89, 179, 179, 179, 179, 179, 179, 179]\n",
      "牧民5洗脸盆洗脸盆洗脸盆洗脸盆洗脸盆洗脸盆洗脸盆\n",
      "[166, 179, 179, 179, 87, 80, 126, 126, 126]\n",
      "教练洗脸盆洗脸盆洗脸盆4034太阳太阳太阳\n",
      "[70, 174, 174, 174, 174, 174, 174, 33, 33]\n",
      "25武警武警武警武警武警武警困难困难\n",
      "[116, 116, 116, 116, 116, 116, 116, 116, 116]\n",
      "发挥发挥发挥发挥发挥发挥发挥发挥发挥\n",
      "[38, 38, 38, 38, 38, 38, 38, 38, 38]\n",
      "婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆\n",
      "[111, 111, 111, 111, 111, 111, 111, 111, 111]\n",
      "加强加强加强加强加强加强加强加强加强\n",
      "[188, 188, 188, 188, 188, 188, 188, 188, 188]\n",
      "现实情况现实情况现实情况现实情况现实情况现实情况现实情况现实情况现实情况\n",
      "[126, 126, 126, 126, 126, 126, 126, 126, 126]\n",
      "太阳太阳太阳太阳太阳太阳太阳太阳太阳\n",
      "[186, 160, 194, 194, 194, 194, 90, 222, 222]\n",
      "环境推荐知识分子知识分子知识分子知识分子6颜色颜色\n",
      "[181, 103, 221, 221, 221, 221, 221, 220, 174]\n",
      "演员保姆项链项链项链项链项链门卫武警\n",
      "[148, 148, 148, 148, 148, 148, 148, 148, 148]\n",
      "形成形成形成形成形成形成形成形成形成\n",
      "[21, 21, 21, 21, 21, 21, 21, 21, 21]\n",
      "妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹\n",
      "[148, 148, 148, 148, 148, 148, 148, 148, 148]\n",
      "形成形成形成形成形成形成形成形成形成\n",
      "[124, 124, 124, 124, 124, 124, 124, 124, 124]\n",
      "天气预报天气预报天气预报天气预报天气预报天气预报天气预报天气预报天气预报\n",
      "[152, 152, 152, 152, 152, 152, 152, 152, 152]\n",
      "手电筒手电筒手电筒手电筒手电筒手电筒手电筒手电筒手电筒\n",
      "[64, 209, 209, 209, 209, 209, 209, 209, 209]\n",
      "2行星行星行星行星行星行星行星行星\n",
      "[51, 51, 51, 51, 51, 9, 173, 173, 173]\n",
      "邻居邻居邻居邻居邻居我们橙色橙色橙色\n",
      "[4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "的的的的的的的的的\n",
      "[73, 133, 133, 133, 131, 131, 216, 153, 153]\n",
      "28安定安定安定嫂嫂嫂嫂贫苦手表手表\n",
      "[129, 129, 129, 129, 129, 129, 32, 32, 32]\n",
      "姐夫姐夫姐夫姐夫姐夫姐夫团结团结团结\n",
      "[111, 111, 111, 111, 111, 111, 111, 111, 111]\n",
      "加强加强加强加强加强加强加强加强加强\n",
      "[103, 50, 50, 50, 50, 50, 50, 50, 50]\n",
      "保姆警察警察警察警察警察警察警察警察\n",
      "[55, 133, 41, 41, 152, 34, 34, 34, 160]\n",
      "11安定形势形势手电筒地球地球地球推荐\n",
      "[12, 12, 12, 12, 12, 12, 12, 12, 12]\n",
      "社会社会社会社会社会社会社会社会社会\n",
      "[7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "我我我我我我我我我\n",
      "[8, 8, 8, 8, 8, 8, 8, 8, 8]\n",
      "你你你你你你你你你\n",
      "[130, 130, 130, 130, 130, 130, 130, 130, 130]\n",
      "姐姐姐姐姐姐姐姐姐姐姐姐姐姐姐姐姐姐\n",
      "[188, 188, 188, 188, 188, 188, 188, 188, 188]\n",
      "现实情况现实情况现实情况现实情况现实情况现实情况现实情况现实情况现实情况\n",
      "[134, 201, 201, 201, 201, 201, 201, 201, 201]\n",
      "容易结果结果结果结果结果结果结果结果\n",
      "[187, 187, 187, 187, 187, 187, 20, 99, 99]\n",
      "现实现实现实现实现实现实基础任务任务\n",
      "[27, 178, 4, 4, 4, 4, 4, 4, 4]\n",
      "目标没有的的的的的的的\n",
      "[110, 27, 27, 203, 203, 123, 123, 123, 123]\n",
      "剪刀目标目标编辑编辑外祖母外祖母外祖母外祖母\n",
      "[19, 19, 19, 19, 19, 19, 19, 19, 19]\n",
      "地位地位地位地位地位地位地位地位地位\n",
      "[21, 21, 21, 21, 21, 21, 21, 21, 21]\n",
      "妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹\n",
      "[171, 171, 171, 171, 171, 171, 171, 171, 200]\n",
      "杯子杯子杯子杯子杯子杯子杯子杯子经验丰富\n",
      "[148, 148, 148, 148, 148, 148, 148, 148, 148]\n",
      "形成形成形成形成形成形成形成形成形成\n",
      "[187, 187, 187, 187, 187, 187, 187, 187, 187]\n",
      "现实现实现实现实现实现实现实现实现实\n",
      "[21, 21, 21, 21, 21, 21, 21, 21, 21]\n",
      "妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹\n",
      "[125, 125, 125, 125, 125, 125, 125, 125, 125]\n",
      "天空天空天空天空天空天空天空天空天空\n",
      "[7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "我我我我我我我我我\n",
      "[171, 171, 171, 171, 171, 171, 112, 88, 182]\n",
      "杯子杯子杯子杯子杯子杯子医生41炊事员\n",
      "[200, 200, 31, 31, 31, 31, 31, 31, 31]\n",
      "经验丰富经验丰富公公公公公公公公公公公公公公\n",
      "[162, 162, 162, 162, 162, 162, 20, 20, 20]\n",
      "摆脱摆脱摆脱摆脱摆脱摆脱基础基础基础\n",
      "[148, 148, 148, 148, 148, 148, 148, 148, 148]\n",
      "形成形成形成形成形成形成形成形成形成\n",
      "[135, 135, 22, 121, 121, 121, 121, 121, 121]\n",
      "富强富强幸福圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功\n",
      "[187, 187, 187, 187, 187, 187, 187, 187, 187]\n",
      "现实现实现实现实现实现实现实现实现实\n",
      "[111, 111, 111, 111, 111, 111, 111, 111, 111]\n",
      "加强加强加强加强加强加强加强加强加强\n",
      "[38, 38, 38, 38, 38, 38, 38, 38, 38]\n",
      "婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆\n",
      "[21, 21, 21, 21, 21, 21, 21, 21, 21]\n",
      "妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹\n",
      "[121, 121, 121, 121, 121, 121, 121, 121, 121]\n",
      "圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功\n",
      "[128, 128, 48, 48, 48, 48, 48, 48, 48]\n",
      "妻子妻子紧张紧张紧张紧张紧张紧张紧张\n",
      "[171, 171, 171, 171, 171, 171, 171, 171, 171]\n",
      "杯子杯子杯子杯子杯子杯子杯子杯子杯子\n",
      "[193, 141, 128, 128, 128, 128, 149, 53, 62]\n",
      "盲人岳父妻子妻子妻子妻子律师118\n",
      "[130, 130, 130, 130, 130, 130, 130, 130, 130]\n",
      "姐姐姐姐姐姐姐姐姐姐姐姐姐姐姐姐姐姐\n",
      "[7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "我我我我我我我我我\n",
      "[201, 201, 201, 201, 201, 201, 201, 201, 201]\n",
      "结果结果结果结果结果结果结果结果结果\n",
      "[119, 119, 119, 119, 119, 119, 119, 119, 119]\n",
      "园丁园丁园丁园丁园丁园丁园丁园丁园丁\n",
      "[64, 217, 217, 12, 12, 12, 12, 12, 215]\n",
      "2邮递员邮递员社会社会社会社会社会记者\n",
      "[139, 139, 139, 139, 139, 139, 214, 214, 184]\n",
      "局势局势局势局势局势局势解放军解放军牧民\n",
      "[4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "的的的的的的的的的\n",
      "[31, 31, 31, 31, 31, 31, 31, 31, 31]\n",
      "公公公公公公公公公公公公公公公公公公\n",
      "[148, 148, 148, 148, 148, 148, 148, 148, 148]\n",
      "形成形成形成形成形成形成形成形成形成\n",
      "[121, 121, 121, 121, 121, 121, 121, 121, 121]\n",
      "圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功圆满成功\n",
      "[164, 164, 164, 164, 164, 164, 164, 164, 164]\n",
      "效益效益效益效益效益效益效益效益效益\n",
      "[210, 210, 210, 83, 23, 23, 23, 23, 23]\n",
      "表哥表哥表哥37提高提高提高提高提高\n",
      "[16, 16, 16, 16, 16, 16, 16, 16, 16]\n",
      "外祖父外祖父外祖父外祖父外祖父外祖父外祖父外祖父外祖父\n",
      "[21, 21, 21, 21, 21, 21, 21, 21, 21]\n",
      "妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹\n",
      "[148, 148, 148, 148, 148, 148, 148, 148, 148]\n",
      "形成形成形成形成形成形成形成形成形成\n",
      "[21, 21, 21, 21, 21, 21, 21, 21, 21]\n",
      "妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹\n",
      "[187, 187, 187, 187, 187, 187, 187, 187, 187]\n",
      "现实现实现实现实现实现实现实现实现实\n",
      "[187, 187, 187, 187, 187, 187, 187, 187, 187]\n",
      "现实现实现实现实现实现实现实现实现实\n",
      "[41, 41, 41, 41, 41, 41, 41, 41, 41]\n",
      "形势形势形势形势形势形势形势形势形势\n",
      "[215, 215, 215, 70, 196, 196, 70, 136, 136]\n",
      "记者记者记者25礼貌礼貌25导演导演\n",
      "[13, 13, 13, 13, 13, 13, 13, 13, 13]\n",
      "国家国家国家国家国家国家国家国家国家\n",
      "[147, 147, 147, 106, 206, 206, 183, 183, 202]\n",
      "弱智人弱智人弱智人公务员职员职员牙刷牙刷绿\n",
      "[124, 124, 124, 124, 124, 124, 124, 124, 124]\n",
      "天气预报天气预报天气预报天气预报天气预报天气预报天气预报天气预报天气预报\n",
      "[47, 47, 47, 47, 47, 47, 47, 47, 47]\n",
      "民主民主民主民主民主民主民主民主民主\n",
      "[212, 212, 214, 214, 195, 32, 32, 32, 32]\n",
      "褐色褐色解放军解放军破团结团结团结团结\n",
      "[4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "的的的的的的的的的\n",
      "[38, 193, 187, 187, 187, 187, 187, 187, 187]\n",
      "婆婆盲人现实现实现实现实现实现实现实\n",
      "[98, 98, 98, 98, 98, 98, 98, 98, 98]\n",
      "他们他们他们他们他们他们他们他们他们\n",
      "[148, 148, 148, 148, 148, 148, 148, 148, 148]\n",
      "形成形成形成形成形成形成形成形成形成\n",
      "[38, 38, 38, 38, 38, 38, 38, 38, 38]\n",
      "婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆\n",
      "[108, 108, 108, 16, 16, 16, 16, 16, 16]\n",
      "刑警刑警刑警外祖父外祖父外祖父外祖父外祖父外祖父\n",
      "[201, 201, 201, 201, 201, 201, 201, 201, 201]\n",
      "结果结果结果结果结果结果结果结果结果\n",
      "[93, 26, 26, 26, 26, 26, 26, 26, 26]\n",
      "9爸爸爸爸爸爸爸爸爸爸爸爸爸爸爸爸\n",
      "[209, 209, 209, 209, 209, 209, 209, 48, 48]\n",
      "行星行星行星行星行星行星行星紧张紧张\n",
      "[171, 171, 171, 171, 171, 171, 171, 171, 171]\n",
      "杯子杯子杯子杯子杯子杯子杯子杯子杯子\n",
      "[221, 221, 221, 86, 172, 121, 4, 4, 4]\n",
      "项链项链项链4模特圆满成功的的的\n",
      "[24, 24, 24, 24, 24, 24, 24, 24, 24]\n",
      "新新新新新新新新新\n",
      "[142, 192, 192, 192, 192, 192, 192, 192, 192]\n",
      "工人盆盆盆盆盆盆盆盆\n",
      "[16, 16, 16, 16, 16, 16, 16, 16, 16]\n",
      "外祖父外祖父外祖父外祖父外祖父外祖父外祖父外祖父外祖父\n",
      "[188, 188, 188, 188, 188, 188, 188, 188, 188]\n",
      "现实情况现实情况现实情况现实情况现实情况现实情况现实情况现实情况现实情况\n",
      "[194, 194, 194, 194, 194, 194, 194, 194, 194]\n",
      "知识分子知识分子知识分子知识分子知识分子知识分子知识分子知识分子知识分子\n",
      "[148, 148, 148, 148, 148, 148, 148, 148, 148]\n",
      "形成形成形成形成形成形成形成形成形成\n",
      "[56, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "12他他他他他他他他\n",
      "[55, 24, 24, 24, 24, 24, 24, 24, 24]\n",
      "11新新新新新新新新\n",
      "[45, 45, 45, 45, 45, 45, 45, 45, 45]\n",
      "残疾人残疾人残疾人残疾人残疾人残疾人残疾人残疾人残疾人\n",
      "[148, 148, 148, 148, 148, 148, 148, 148, 148]\n",
      "形成形成形成形成形成形成形成形成形成\n",
      "[204, 204, 147, 147, 147, 147, 147, 134, 189]\n",
      "美容美容弱智人弱智人弱智人弱智人弱智人容易电池\n",
      "[38, 38, 38, 38, 38, 38, 38, 38, 38]\n",
      "婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆婆\n",
      "[170, 137, 137, 137, 172, 66, 120, 5, 5]\n",
      "来小孩子小孩子小孩子模特21国民是是\n",
      "[48, 48, 48, 48, 48, 48, 48, 48, 48]\n",
      "紧张紧张紧张紧张紧张紧张紧张紧张紧张\n",
      "[119, 119, 119, 119, 33, 33, 33, 68, 148]\n",
      "园丁园丁园丁园丁困难困难困难23形成\n",
      "[167, 85, 28, 28, 28, 28, 28, 28, 28]\n",
      "星星39祖父祖父祖父祖父祖父祖父祖父\n",
      "[16, 16, 16, 16, 16, 16, 16, 16, 16]\n",
      "外祖父外祖父外祖父外祖父外祖父外祖父外祖父外祖父外祖父\n",
      "[16, 16, 16, 16, 16, 16, 16, 16, 16]\n",
      "外祖父外祖父外祖父外祖父外祖父外祖父外祖父外祖父外祖父\n",
      "[9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "我们我们我们我们我们我们我们我们我们\n",
      "[198, 93, 49, 49, 49, 49, 49, 49, 49]\n",
      "空9裁缝裁缝裁缝裁缝裁缝裁缝裁缝\n",
      "[45, 45, 129, 129, 129, 129, 129, 129, 129]\n",
      "残疾人残疾人姐夫姐夫姐夫姐夫姐夫姐夫姐夫\n",
      "[21, 21, 21, 21, 21, 21, 21, 21, 21]\n",
      "妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹\n",
      "[175, 186, 180, 180, 97, 97, 97, 97, 97]\n",
      "歪环境深深他人他人他人他人他人\n",
      "[139, 139, 139, 139, 139, 139, 139, 139, 9]\n",
      "局势局势局势局势局势局势局势局势我们\n",
      "[77, 128, 128, 128, 128, 48, 48, 48, 48]\n",
      "31妻子妻子妻子妻子紧张紧张紧张紧张\n",
      "[24, 24, 24, 24, 24, 24, 24, 24, 24]\n",
      "新新新新新新新新新\n",
      "[19, 19, 19, 19, 19, 19, 19, 19, 19]\n",
      "地位地位地位地位地位地位地位地位地位\n",
      "[186, 186, 186, 104, 104, 104, 104, 104, 27]\n",
      "环境环境环境保安保安保安保安保安目标\n",
      "[140, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "岗位<end><end><end><end><end><end><end><end>\n",
      "[21, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "妹妹丈夫丈夫丈夫丈夫丈夫丈夫丈夫丈夫\n",
      "[148, 148, 148, 148, 148, 148, 148, 148, 211]\n",
      "形成形成形成形成形成形成形成形成被子\n",
      "[12, 12, 12, 12, 12, 12, 12, 12, 12]\n",
      "社会社会社会社会社会社会社会社会社会\n",
      "[41, 41, 41, 41, 41, 41, 41, 41, 41]\n",
      "形势形势形势形势形势形势形势形势形势\n",
      "[160, 197, 15, 15, 15, 15, 15, 15, 15]\n",
      "推荐祖母哥哥哥哥哥哥哥哥哥哥哥哥哥哥\n",
      "[108, 108, 108, 108, 108, 197, 197, 197, 197]\n",
      "刑警刑警刑警刑警刑警祖母祖母祖母祖母\n",
      "[171, 171, 171, 171, 171, 171, 171, 171, 171]\n",
      "杯子杯子杯子杯子杯子杯子杯子杯子杯子\n",
      "[162, 171, 171, 45, 45, 213, 158, 158, 158]\n",
      "摆脱杯子杯子残疾人残疾人观察拜访拜访拜访\n",
      "[12, 12, 12, 12, 12, 12, 12, 12, 12]\n",
      "社会社会社会社会社会社会社会社会社会\n",
      "[19, 19, 19, 19, 19, 19, 19, 19, 19]\n",
      "地位地位地位地位地位地位地位地位地位\n",
      "[21, 21, 21, 21, 21, 21, 21, 21, 21]\n",
      "妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹妹\n",
      "[124, 124, 124, 124, 124, 124, 124, 124, 124]\n",
      "天气预报天气预报天气预报天气预报天气预报天气预报天气预报天气预报天气预报\n",
      "[124, 124, 124, 124, 181, 181, 33, 33, 33]\n",
      "天气预报天气预报天气预报天气预报演员演员困难困难困难\n",
      "[38, 38, 38, 38, 38, 38, 38, 45, 45]\n",
      "婆婆婆婆婆婆婆婆婆婆婆婆婆婆残疾人残疾人\n",
      "[208, 208, 208, 208, 208, 208, 208, 208, 208]\n",
      "茶壶茶壶茶壶茶壶茶壶茶壶茶壶茶壶茶壶\n",
      "[148, 148, 148, 148, 148, 148, 148, 148, 4]\n",
      "形成形成形成形成形成形成形成形成的\n",
      "[146, 146, 45, 45, 45, 45, 45, 45, 45]\n",
      "弟弟弟弟残疾人残疾人残疾人残疾人残疾人残疾人残疾人\n",
      "[147, 160, 160, 160, 160, 113, 146, 139, 139]\n",
      "弱智人推荐推荐推荐推荐卫星弟弟局势局势\n",
      "[148, 148, 148, 148, 148, 148, 148, 148, 148]\n",
      "形成形成形成形成形成形成形成形成形成\n",
      "[222, 222, 222, 222, 222, 222, 222, 222, 222]\n",
      "颜色颜色颜色颜色颜色颜色颜色颜色颜色\n",
      "[43, 43, 31, 5, 5, 5, 5, 5, 5]\n",
      "护士护士公公是是是是是是\n",
      "[106, 150, 213, 213, 4, 4, 4, 4, 4]\n",
      "公务员恒星观察观察的的的的的\n",
      "[74, 126, 126, 126, 126, 126, 126, 126, 126]\n",
      "29太阳太阳太阳太阳太阳太阳太阳太阳\n",
      "[162, 162, 162, 162, 162, 162, 162, 48, 48]\n",
      "摆脱摆脱摆脱摆脱摆脱摆脱摆脱紧张紧张\n",
      "[25, 25, 25, 25, 25, 25, 25, 25, 25]\n",
      "朋友朋友朋友朋友朋友朋友朋友朋友朋友\n",
      "[101, 33, 33, 105, 105, 105, 76, 174, 174]\n",
      "会计困难困难保育员保育员保育员30武警武警\n",
      "[16, 16, 16, 16, 16, 16, 16, 16, 16]\n",
      "外祖父外祖父外祖父外祖父外祖父外祖父外祖父外祖父外祖父\n",
      "[33, 33, 33, 33, 33, 33, 33, 33, 33]\n",
      "困难困难困难困难困难困难困难困难困难\n",
      "[124, 124, 124, 124, 124, 124, 124, 124, 124]\n",
      "天气预报天气预报天气预报天气预报天气预报天气预报天气预报天气预报天气预报\n",
      "[179, 179, 179, 179, 179, 179, 179, 179, 179]\n",
      "洗脸盆洗脸盆洗脸盆洗脸盆洗脸盆洗脸盆洗脸盆洗脸盆洗脸盆\n",
      "[158, 164, 164, 164, 202, 165, 19, 19, 26]\n",
      "拜访效益效益效益绿教师地位地位爸爸\n",
      "[37, 37, 37, 37, 37, 37, 37, 37, 37]\n",
      "好好好好好好好好好\n",
      "[171, 171, 171, 171, 171, 171, 171, 171, 171]\n",
      "杯子杯子杯子杯子杯子杯子杯子杯子杯子\n",
      "[210, 210, 210, 210, 210, 210, 210, 210, 210]\n",
      "表哥表哥表哥表哥表哥表哥表哥表哥表哥\n",
      "[91, 148, 49, 49, 49, 49, 49, 49, 49]\n",
      "7形成裁缝裁缝裁缝裁缝裁缝裁缝裁缝\n",
      "[2, 133, 132, 132, 132, 132, 132, 132, 219]\n",
      "<unk>安定学生学生学生学生学生学生锋利\n",
      "[49, 49, 49, 49, 49, 49, 49, 49, 49]\n",
      "裁缝裁缝裁缝裁缝裁缝裁缝裁缝裁缝裁缝\n",
      "[102, 102, 102, 102, 117, 117, 117, 117, 203]\n",
      "保卫保卫保卫保卫向导向导向导向导编辑\n",
      "[171, 171, 171, 171, 171, 171, 171, 171, 171]\n",
      "杯子杯子杯子杯子杯子杯子杯子杯子杯子\n",
      "[32, 32, 32, 32, 159, 159, 159, 159, 159]\n",
      "团结团结团结团结捐献捐献捐献捐献捐献\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F  # 添加这行导入\n",
    "for src, trg in train_loader:\n",
    "    src = src.to(device)\n",
    "    trg = trg.to(device)\n",
    "    output = model.predict(src)\n",
    "    output = output[0].tolist()\n",
    "    print(output)\n",
    "    text = ''\n",
    "    for i in output:\n",
    "        text+=idx2word[i]\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15e3932a-4bc5-4733-a958-b773f96f382e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class seq2seq(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim,output_dim,n_layers):\n",
    "        super().__init__()\n",
    "        self.encode_embedding = nn.Embedding(input_dim, emb_dim) #将每个词扩充为emb_dim维\n",
    "        self.decode_embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.encode = nn.LSTM(emb_dim, hidden_dim, n_layers)\n",
    "        self.decode = nn.LSTM(emb_dim,hidden_dim, n_layers)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "#     def forward(self, src,tar):\n",
    "#         # src: [batch_size, src_len]\n",
    "#         # trg: [batch_size, trg_len]\n",
    "#         encode_embedded = self.encode_embedding(src)  # [batch_size, src_len, emb_dim]\n",
    "#         encode_embedded = encode_embedded.permute(1, 0, 2) \n",
    "#         print(f'embedded:{encode_embedded.size()}')\n",
    "#         outputs, (hidden, cell) = self.encode(encode_embedded)\n",
    "#         print(f'encode outputs:{outputs.size()}')\n",
    "#         print(f'encode hidden:{hidden.size()}')\n",
    "#         decode_embedded = self.decode_embedding(tar) \n",
    "#         print(f'decode embedden:{decode_embedded.size()}')\n",
    "#         # outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
    "        \n",
    "#         # outputs,_ = self.decode(hidden)\n",
    "#         return hidden\n",
    "    def forward(self, src, tar):\n",
    "        # src: [batch_size, src_len]\n",
    "        # tar: [batch_size, trg_len]\n",
    "        \n",
    "        # 编码器部分\n",
    "        encode_embedded = self.encode_embedding(src)  # [batch_size, src_len, emb_dim]\n",
    "        encode_embedded = encode_embedded.permute(1, 0, 2)  # [src_len, batch_size, emb_dim]\n",
    "        _, (hidden, cell) = self.encode(encode_embedded)\n",
    "        \n",
    "        # 解码器部分\n",
    "        batch_size = tar.shape[0] #3\n",
    "        trg_len = tar.shape[1] #9\n",
    "        output_dim = self.fc.out_features #181\n",
    "        print(output_dim)\n",
    "        \n",
    "        # 准备输出张量\n",
    "        outputs = torch.zeros(trg_len, batch_size, output_dim).to(src.device)#9x3x181\n",
    "        \n",
    "        # 初始输入是<sos> token，这里假设tar已经包含<sos>作为第一个token\n",
    "        input = tar[:, 0]  # 取第一个token作为初始输入 [batch_size]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            # 嵌入输入\n",
    "            embedded = self.decode_embedding(input).unsqueeze(0)  # [1, batch_size, emb_dim]\n",
    "            print(f'embedded:{embedded.size()}')\n",
    "            print(f'hidden:{hidden.size()}')\n",
    "            # 通过解码器\n",
    "            output, (hidden, cell) = self.decode(embedded, (hidden, cell))\n",
    "            \n",
    "            # 预测下一个token\n",
    "            pred = self.fc(output.squeeze(0))\n",
    "            outputs[t] = pred\n",
    "            \n",
    "            # 下一个输入是真实目标(teacher forcing)或预测结果\n",
    "            # 这里使用teacher forcing，传入真实目标\n",
    "            input = tar[:, t]\n",
    "        \n",
    "        return outputs.permute(1, 0, 2)  # [batch_size, trg_len, output_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4aa861a0-d00f-4846-a38a-c200065c44ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 9])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f4d04e70-4d5a-452a-a078-77231a1e800e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([47,  6, 74])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4dff98-5436-4675-aeee-1f2a551aac24",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data =all_data \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx][1]\n",
    "        label = self.data[idx][0]\n",
    "        return sample, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "10039ced-ba68-46b8-b85f-94d093d0b34a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义划分比例（例如80%训练，20%测试）\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "# 随机划分\n",
    "train_dataset, test_dataset = random_split(\n",
    "    dataset, \n",
    "    [train_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)  # 固定随机种子确保可复现\n",
    ")\n",
    "\n",
    "# 创建DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=3, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e0a0af9-5dc9-4048-88d7-57996ab05072",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([18, 18, 26, 18, 26, 18, 26, 18, 26, 18, 26, 18, 26, 18, 26, 18, 26, 18,\n",
       "         26, 18, 26, 18, 26, 18, 26, 18, 26, 18, 26, 18, 26, 18, 26, 18, 26, 18,\n",
       "         26, 18, 26, 18, 26, 18, 26, 18, 26, 18, 26, 18, 26, 18, 26, 18, 26, 18,\n",
       "         26, 26, 18, 18, 18, 18, 24, 18, 24, 24, 18, 18, 18, 18, 18, 18, 28, 18,\n",
       "         35, 18, 38, 18, 38, 18, 38, 18, 38, 38, 38, 18, 38, 38, 38, 18, 38, 38,\n",
       "         38, 18, 38, 38, 38, 18, 38, 38, 38, 18, 38, 38, 38, 18, 38, 38, 38, 18,\n",
       "         38, 18, 38, 18, 38, 18, 35, 18, 31, 35, 31, 35, 28, 35, 28, 35, 35, 19,\n",
       "          4, 18,  4, 18, 28,  4, 35,  4, 35, 18,  6, 18, 38,  5,  1, 18,  1, 18,\n",
       "          1, 18,  1,  1,  1, 18,  1, 18,  1, 18,  1,  1,  1, 18,  1,  1, 34, 18,\n",
       "          6, 34, 34, 18, 38, 34, 34, 18,  1, 18, 16, 18, 18, 18, 18, 18, 18, 18,\n",
       "         18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
       "         18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 32, 18, 27, 18, 12, 18, 12, 18,\n",
       "         12, 18, 12,  1,  1, 18,  1,  1,  1, 12,  1, 12, 13, 12, 13, 12, 13, 12,\n",
       "         13, 12, 13, 12, 13, 12, 13, 12, 13, 12,  1, 12,  1, 12,  1, 12,  1, 12,\n",
       "          1, 12,  1, 12,  1, 12,  1, 12,  1, 12,  1, 12,  1,  1,  1,  1, 20, 18,\n",
       "         20, 18, 20, 36, 17, 18, 16, 18, 16, 18, 27, 18, 31, 18, 13, 18, 13, 18,\n",
       "         13, 18, 31, 18, 38, 18, 38, 18, 38, 18, 35, 18, 34, 18, 34, 18, 34, 34,\n",
       "         34, 18, 34, 18, 34, 18, 34, 18, 34, 18, 34, 18, 34, 34, 34, 18, 34, 34,\n",
       "         34, 18, 34, 20, 20, 18, 34, 20, 20, 18, 34, 20, 20, 18, 16,  7,  7, 18,\n",
       "          7,  7, 18, 18, 18, 18, 18, 18,  7, 18,  7, 18,  7, 18,  7, 18,  7, 18,\n",
       "          7, 18,  7, 18,  7, 18,  7, 18,  7, 18,  7, 18, 20, 18, 20, 18, 20, 18,\n",
       "         20, 18, 20, 18, 20, 18, 20, 18,  7, 20, 20, 18, 16, 20, 18, 18, 18, 18,\n",
       "         18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
       "         18, 18, 18, 18, 18, 18, 18, 18, 18, 18], dtype=torch.int32),\n",
       " tensor([ 5,  3,  9,  4, 49,  2,  0,  0]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdf01de-85b9-48ed-92da-d4473b22c4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "e7fdcfc6-ace0-4514-93d0-19a4fb11b8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# class Seq2SeqTransformer(nn.Module):\n",
    "#     def __init__(self, input_dim, output_dim, d_model=512, nhead=8, num_layers=6):\n",
    "#         super().__init__()\n",
    "#         self.encoder = nn.Linear(input_dim, d_model)\n",
    "#         self.decoder = nn.Linear(d_model, output_dim)\n",
    "#         self.transformer = nn.Transformer(\n",
    "#             d_model=d_model,\n",
    "#             nhead=nhead,\n",
    "#             num_encoder_layers=num_layers,\n",
    "#             num_decoder_layers=num_layers\n",
    "#         )\n",
    "#         self.pos_encoder = PositionalEncoding(d_model)  # 需自定义\n",
    "\n",
    "#     def forward(self, src, tgt):\n",
    "#         # src: (seq_len, batch, input_dim)\n",
    "#         src = self.encoder(src)  # (seq_len, batch, d_model)\n",
    "#         src = self.pos_encoder(src)\n",
    "#         tgt = self.pos_encoder(tgt)  # 假设tgt是decoder输入\n",
    "#         output = self.transformer(src, tgt)\n",
    "#         return self.decoder(output)\n",
    "\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, output_size, d_model=128, nhead=4, num_layers=3):\n",
    "        super().__init__()\n",
    "        self.src_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.tgt_embedding = nn.Embedding(output_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers\n",
    "        )\n",
    "        self.decoder = nn.Linear(d_model, output_size)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        # 确保输入至少有3维\n",
    "        if src.dim() == 2:\n",
    "            src = src.unsqueeze(1)  # (seq_len, 1, input_dim)\n",
    "        if tgt.dim() == 2:\n",
    "            tgt = tgt.unsqueeze(1)  # (seq_len, 1, output_dim)\n",
    "\n",
    "        src = self.pos_encoder(self.src_embedding(src))\n",
    "        tgt = self.pos_encoder(self.tgt_embedding(tgt))\n",
    "        output = self.transformer(src, tgt)\n",
    "        return self.decoder(output)\n",
    "\n",
    "# 位置编码（Transformer需要）\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pe = self.pe[:x.size(0)].unsqueeze(1)\n",
    "        x = x + pe\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.encoder = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.decoder = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        embedded = embedded.permute(1, 0, 2) \n",
    "        _, (hidden, cell) = self.encoder(embedded)\n",
    "        output, _ = self.decoder(embedded, (hidden, cell))\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "15d55c09-a589-447c-a2ba-3228179565ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.encoder = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.decoder = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        embedded = embedded.permute(1, 0, 2) \n",
    "        _, (hidden, cell) = self.encoder(embedded)\n",
    "        output, _ = self.decoder(embedded, (hidden, cell))\n",
    "        # output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c5deb7-3956-4c7d-9218-561bde25c963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, max_output_len=8):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.encoder = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.decoder = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.max_output_len = max_output_len  # 固定输出长度8\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        embedded = self.embedding(x)  # [batch, 424, hidden_size]\n",
    "        _, (hidden, cell) = self.encoder(embedded)  # hidden: [1, batch, hidden_size]\n",
    "\n",
    "        # Decoder初始化\n",
    "        batch_size = x.size(0)\n",
    "        decoder_input = torch.zeros(batch_size, 1, dtype=torch.long).to(x.device)  # 初始输入<SOS>（假设0是<SOS>）\n",
    "        outputs = torch.zeros(batch_size, self.max_output_len, self.output_size).to(x.device)\n",
    "\n",
    "        # 自回归生成（逐步预测）\n",
    "        for t in range(self.max_output_len):\n",
    "            decoder_embedded = self.embedding(decoder_input)  # [batch, 1, hidden_size]\n",
    "            decoder_output, (hidden, cell) = self.decoder(decoder_embedded, (hidden, cell))\n",
    "            output = self.fc(decoder_output.squeeze(1))  # [batch, output_size]\n",
    "            outputs[:, t, :] = output\n",
    "\n",
    "            # 下一步输入是当前预测的token（Teacher Forcing可选）\n",
    "            decoder_input = output.argmax(-1).unsqueeze(1)  # [batch, 1]\n",
    "\n",
    "        return outputs  # [batch, 8, output_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1314d6d0-1b07-4c27-9b39-9bf2a4bcfe4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vocab_size = 40  # 词汇表大小（根据你的token ID最大值38，建议取稍大的值如50）\n",
    "# output_size = 180  # 输出维度（与词汇表大小一致，如果是分类任务）\n",
    "\n",
    "# model = Seq2SeqTransformer(vocab_size=vocab_size, output_size=output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "dc700a1d-cdf7-4fe3-8bc9-fb74c49a802c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_size = 40\n",
    "hidden_size = 64\n",
    "output_size = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "ffb5a17a-1ba8-46ed-b9e5-41ed811529ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Seq2Seq(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "e36efc20-7f73-4ca7-aa64-d0db51a3c08c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[271], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (8, 1, 50)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[268], line 11\u001b[0m, in \u001b[0;36mSeq2Seq.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     10\u001b[0m     embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\n\u001b[0;32m---> 11\u001b[0m     embedded \u001b[38;5;241m=\u001b[39m \u001b[43membedded\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m     12\u001b[0m     _, (hidden, cell) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(embedded)\n\u001b[1;32m     13\u001b[0m     output, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(embedded, (hidden, cell))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 3"
     ]
    }
   ],
   "source": [
    "output = model(src)  # (8, 1, 50)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7ea871bc-8736-4014-81b4-ef7c1a59fb1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 424])\n",
      "torch.Size([2, 8])\n",
      "torch.Size([2, 424, 180])\n"
     ]
    }
   ],
   "source": [
    "model = Seq2Seq(input_size, hidden_size, output_size)\n",
    "for input_tensor, target_tensor in train_loader:\n",
    "        print(input_tensor.size())\n",
    "        print(target_tensor.size())\n",
    "        output = model(input_tensor)\n",
    "        print(output.size())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f182d0-104d-4371-8fbc-82f2a4e6d368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c9468d9b-bbff-4dd8-9c12-861c038640bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "src = torch.tensor([18, 18, 26, 18, 26, 18, 26, 18, 26, 18, 26, 18, 26, 18, 26, 18, 26, 18,\n",
    "         26, 18, 26, 18, 26, 18, 26, 18, 26, 18, 26, 18, 26, 18, 26, 18, 26, 18,\n",
    "         26, 18, 26, 18, 26, 18, 26, 18, 26, 18, 26, 18, 26, 18, 26, 18, 26, 18,\n",
    "         26, 26, 18, 18, 18, 18, 24, 18, 24, 24, 18, 18, 18, 18, 18, 18, 28, 18,\n",
    "         35, 18, 38, 18, 38, 18, 38, 18, 38, 38, 38, 18, 38, 38, 38, 18, 38, 38,\n",
    "         38, 18, 38, 38, 38, 18, 38, 38, 38, 18, 38, 38, 38, 18, 38, 38, 38, 18,\n",
    "         38, 18, 38, 18, 38, 18, 35, 18, 31, 35, 31, 35, 28, 35, 28, 35, 35, 19,\n",
    "          4, 18,  4, 18, 28,  4, 35,  4, 35, 18,  6, 18, 38,  5,  1, 18,  1, 18,\n",
    "          1, 18,  1,  1,  1, 18,  1, 18,  1, 18,  1,  1,  1, 18,  1,  1, 34, 18,\n",
    "          6, 34, 34, 18, 38, 34, 34, 18,  1, 18, 16, 18, 18, 18, 18, 18, 18, 18,\n",
    "         18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
    "         18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 32, 18, 27, 18, 12, 18, 12, 18,\n",
    "         12, 18, 12,  1,  1, 18,  1,  1,  1, 12,  1, 12, 13, 12, 13, 12, 13, 12,\n",
    "         13, 12, 13, 12, 13, 12, 13, 12, 13, 12,  1, 12,  1, 12,  1, 12,  1, 12,\n",
    "          1, 12,  1, 12,  1, 12,  1, 12,  1, 12,  1, 12,  1,  1,  1,  1, 20, 18,\n",
    "         20, 18, 20, 36, 17, 18, 16, 18, 16, 18, 27, 18, 31, 18, 13, 18, 13, 18,\n",
    "         13, 18, 31, 18, 38, 18, 38, 18, 38, 18, 35, 18, 34, 18, 34, 18, 34, 34,\n",
    "         34, 18, 34, 18, 34, 18, 34, 18, 34, 18, 34, 18, 34, 34, 34, 18, 34, 34,\n",
    "         34, 18, 34, 20, 20, 18, 34, 20, 20, 18, 34, 20, 20, 18, 16,  7,  7, 18,\n",
    "          7,  7, 18, 18, 18, 18, 18, 18,  7, 18,  7, 18,  7, 18,  7, 18,  7, 18,\n",
    "          7, 18,  7, 18,  7, 18,  7, 18,  7, 18,  7, 18, 20, 18, 20, 18, 20, 18,\n",
    "         20, 18, 20, 18, 20, 18, 20, 18,  7, 20, 20, 18, 16, 20, 18, 18, 18, 18,\n",
    "         18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
    "         18, 18, 18, 18, 18, 18, 18, 18, 18, 18])\n",
    "tgt = torch.tensor([ 5,  3,  9,  4, 49,  2,  0,  0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ccd9376f-5db8-4f54-bcb1-161ff9bd7f71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "src = torch.tensor([list(src),list(src)])\n",
    "tgt = torch.tensor([list(tgt),list(tgt)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "08596ac8-eb3e-407f-8911-a310cee29e4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = model(src)  # (8, 1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "eadfb7d9-bfb5-403b-9ee2-b12c73ffdcbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 424, 180])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "de711765-aa68-4c75-913f-89e0fdc9d67e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4f730f07-73b7-43c4-85c5-22a692d1a652",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 180])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bff2ae2b-8b52-4c56-8927-7c04735f225f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)  # 忽略padding值（假设0是padding）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7540d0c6-0727-4474-83a7-a2b4efa16b68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/464 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "424\n",
      "tensor([[  5,  87,   3,  26,   4, 129,   2,   0],\n",
      "        [  5,  20,   3,   9,   4, 106,   2,   0],\n",
      "        [105,  28,   3,  19,   2,   0,   0,   0],\n",
      "        [  7,  27,   4, 151,   2,   0,   0,   0],\n",
      "        [  8, 115,  15,   2,   0,   0,   0,   0],\n",
      "        [ 23,   3, 168,   4, 152,   3,   2,   0],\n",
      "        [ 13, 121,  28,  22,   2,   0,   0,   0],\n",
      "        [ 48,  10, 175,   2,   0,   0,   0,   0],\n",
      "        [  5, 154,   4, 162,   2,   0,   0,   0],\n",
      "        [112,   4,  32,   3,   2,   0,   0,   0],\n",
      "        [ 55,   3,  12, 119, 173,   2,   0,   0],\n",
      "        [  7,  27,   4, 151,   2,   0,   0,   0],\n",
      "        [ 68,  12,   3,  59,   2,   0,   0,   0],\n",
      "        [ 13, 121,  28,  22,   2,   0,   0,   0],\n",
      "        [  5,   3,  80,   4,  76,   2,   0,   0],\n",
      "        [  6,   3,  23,  95,   4, 132,   3,   2],\n",
      "        [  6,   3,  17,   4,  93,   2,   0,   0],\n",
      "        [ 67,   4, 176,   3,   2,   0,   0,   0],\n",
      "        [  8,   3,  38,   4,  21,   3,   2,   0],\n",
      "        [  5,  98,   4,  44,   2,   0,   0,   0],\n",
      "        [  6, 167,   3,  50,   4, 172,   2,   0],\n",
      "        [  7,  14,   4, 131,   2,   0,   0,   0],\n",
      "        [  6, 117,   5,  71,  39,   2,   0,   0],\n",
      "        [  5,  15,   4, 174,   2,   0,   0,   0],\n",
      "        [ 48,  10, 175,   2,   0,   0,   0,   0],\n",
      "        [  8, 116,   3,   4,  45,   2,   0,   0],\n",
      "        [ 77,   3,  38,  21,   2,   0,   0,   0],\n",
      "        [  5,   3, 149,   4, 159,   3,   2,   0],\n",
      "        [ 73,   8,   3,  57,   2,   0,   0,   0],\n",
      "        [179,   4,  51,   3,   2,   0,   0,   0],\n",
      "        [  6,  29,   4, 163,   2,   0,   0,   0],\n",
      "        [170,   5,   3,  41,   2,   0,   0,   0]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (424) must match the size of tensor b (32) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m tgt_output \u001b[38;5;241m=\u001b[39m tgt[\u001b[38;5;241m1\u001b[39m:, :]   \u001b[38;5;66;03m# 去掉第一个token\u001b[39;00m\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 17\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_input\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (seq_len, batch, vocab_size)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# 计算损失（忽略padding）\u001b[39;00m\n\u001b[1;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, output\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), \n\u001b[1;32m     21\u001b[0m                tgt_output\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 39\u001b[0m, in \u001b[0;36mSeq2SeqTransformer.forward\u001b[0;34m(self, src, tgt)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, src, tgt):\n\u001b[0;32m---> 39\u001b[0m     src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msrc_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (src_len, batch, d_model)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     tgt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoder(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtgt_embedding(tgt))  \u001b[38;5;66;03m# (tgt_len, batch, d_model)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(src, tgt)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 56\u001b[0m, in \u001b[0;36mPositionalEncoding.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 56\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpe\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (424) must match the size of tensor b (32) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "n_epochs = 40\n",
    "for epoch in range(n_epochs):\n",
    "    # 训练阶段\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for src, tgt in tqdm(train_loader, desc=f'Epoch {epoch+1}'):\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        print(len(src))\n",
    "        print(len(src[0]))\n",
    "        print(tgt)\n",
    "\n",
    "        # 准备decoder输入（shifted right）\n",
    "        tgt_input = tgt[:-1, :]  # 去掉最后一个token\n",
    "        tgt_output = tgt[1:, :]   # 去掉第一个token\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, tgt_input)  # (seq_len, batch, vocab_size)\n",
    "\n",
    "        # 计算损失（忽略padding）\n",
    "        loss = criterion(output.view(-1, output.size(-1)), \n",
    "                       tgt_output.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # 验证阶段\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in val_loader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            tgt_input = tgt[:-1, :]\n",
    "            tgt_output = tgt[1:, :]\n",
    "\n",
    "            output = model(src, tgt_input)\n",
    "            loss = criterion(output.view(-1, output.size(-1)), \n",
    "                           tgt_output.reshape(-1))\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    # 打印日志\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f'Epoch {epoch+1}: Train Loss={avg_train_loss:.4f}, Val Loss={avg_val_loss:.4f}')\n",
    "\n",
    "    # 保存最佳模型\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877324c7-8a44-47ad-b01b-7bcf4f1e9823",
   "metadata": {},
   "source": [
    "#### import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm  # 进度条工具\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)  # 忽略padding值（假设0是padding）\n",
    "    \n",
    "    # 开始训练\n",
    "    trained_model = train_model(\n",
    "        model, train_data, val_data, \n",
    "        optimizer, criterion,\n",
    "        n_epochs=10, batch_size=2, device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb7e638-ed33-4215-b831-60e2e5a927fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabb1655-4031-4cbf-b823-5355bb805af1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05d6b35-c2f5-4754-9395-c93e6ba13cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5e32c2a3-4ed8-4450-8d9d-c3466baa46e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        _, (hidden, cell) = self.lstm(x)\n",
    "        return hidden, cell\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, hidden_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(output_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x, hidden, cell):\n",
    "        output, (hidden, cell) = self.lstm(x, (hidden, cell))\n",
    "        prediction = self.fc(output)\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
    "        batch_size = target.shape[0]\n",
    "        target_len = target.shape[1]\n",
    "        target_dim = target.shape[2]\n",
    "        \n",
    "        # 存储输出\n",
    "        outputs = torch.zeros(batch_size, target_len, target_dim).to(self.device)\n",
    "        \n",
    "        # 编码器处理\n",
    "        hidden, cell = self.encoder(source)\n",
    "        \n",
    "        # 第一个输入是起始token (全零)\n",
    "        input = torch.zeros(batch_size, 1, target_dim).to(self.device)\n",
    "        \n",
    "        for t in range(target_len):\n",
    "            # 解码器一步\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            \n",
    "            # 存储预测\n",
    "            outputs[:, t:t+1] = output\n",
    "            \n",
    "            # 决定是否使用teacher forcing\n",
    "            teacher_force = np.random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            # 如果使用teacher forcing，下一个输入是真实值；否则使用预测值\n",
    "            input = target[:, t:t+1] if teacher_force else output\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9011533a-c299-4183-a013-647706b8a428",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[133], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m best_valid_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[0;32m---> 64\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     valid_loss \u001b[38;5;241m=\u001b[39m evaluate(model, val_loader, criterion)\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# 保存最佳模型\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[133], line 26\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m     22\u001b[0m src, trg \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mto(device), trg\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 26\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, trg)\n\u001b[1;32m     30\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[132], line 31\u001b[0m, in \u001b[0;36mSeq2Seq.forward\u001b[0;34m(self, source, target, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     29\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     30\u001b[0m target_len \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 31\u001b[0m target_dim \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# 存储输出\u001b[39;00m\n\u001b[1;32m     34\u001b[0m outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(batch_size, target_len, target_dim)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# 参数设置\n",
    "input_dim = 424  # 输入特征维度\n",
    "output_dim = 8  # 输出特征维度\n",
    "hidden_dim = 256\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 初始化模型\n",
    "encoder = Encoder(input_dim, hidden_dim)\n",
    "decoder = Decoder(output_dim, hidden_dim)\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "# 定义优化器和损失函数\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.MSELoss()  # 对于回归任务\n",
    "\n",
    "# 训练函数\n",
    "def train(model, dataloader, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, (src, trg) in enumerate(train_loader):\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # 梯度裁剪防止爆炸\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "# 验证函数\n",
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (src, trg) in enumerate(test_loader):\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "            \n",
    "            output = model(src, trg, 0)  # 关闭teacher forcing\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "# 训练循环\n",
    "n_epochs = 100\n",
    "clip = 1\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, clip)\n",
    "    valid_loss = evaluate(model, val_loader, criterion)\n",
    "    \n",
    "    # 保存最佳模型\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "    print(f'\\tVal. Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466787bf-1455-4612-ba79-ab0542d5a6f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
