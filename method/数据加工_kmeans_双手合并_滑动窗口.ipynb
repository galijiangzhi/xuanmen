{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1082ba75-937f-42f7-a67f-1eb343329e7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.4 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_137/4014969775.py\", line 3, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/matplotlib/__init__.py\", line 131, in <module>\n",
      "    from . import _api, _version, cbook, _docstring, rcsetup\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/matplotlib/rcsetup.py\", line 27, in <module>\n",
      "    from matplotlib.colors import Colormap, is_color_like\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/matplotlib/colors.py\", line 56, in <module>\n",
      "    from matplotlib import _api, _cm, cbook, scale\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/matplotlib/scale.py\", line 22, in <module>\n",
      "    from matplotlib.ticker import (\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/matplotlib/ticker.py\", line 138, in <module>\n",
      "    from matplotlib import transforms as mtransforms\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/matplotlib/transforms.py\", line 49, in <module>\n",
      "    from matplotlib._path import (\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMeans\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/__init__.py:131\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sanitize_sequence\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/rcsetup.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Colormap, is_color_like\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fontconfig_pattern\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_fontconfig_pattern\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/colors.py:56\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _cm, cbook, scale\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_color_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BASE_COLORS, TABLEAU_COLORS, CSS4_COLORS, XKCD_COLORS\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_ColorMapping\u001b[39;00m(\u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/scale.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _docstring\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mticker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     NullFormatter, ScalarFormatter, LogFormatterSciNotation, LogitFormatter,\n\u001b[1;32m     24\u001b[0m     NullLocator, LogLocator, AutoLocator, AutoMinorLocator,\n\u001b[1;32m     25\u001b[0m     SymmetricalLogLocator, AsinhLocator, LogitLocator)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Transform, IdentityTransform\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mScaleBase\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/ticker.py:138\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[0;32m--> 138\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms \u001b[38;5;28;01mas\u001b[39;00m mtransforms\n\u001b[1;32m    140\u001b[0m _log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    142\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTickHelper\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFixedFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    143\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNullFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFuncFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatStrFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    144\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStrMethodFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScalarFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultipleLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaxNLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutoMinorLocator\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    151\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSymmetricalLogLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAsinhLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogitLocator\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/transforms.py:49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inv\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_path\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     50\u001b[0m     affine_transform, count_bboxes_overlapping_bbox, update_path_extents)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m     53\u001b[0m DEBUG \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import load\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c93e9de-2e1a-415c-94af-e546cd5a0d54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 2.2.4\n",
      "Uninstalling numpy-2.2.4:\n",
      "  Would remove:\n",
      "    /opt/conda/bin/f2py\n",
      "    /opt/conda/bin/numpy-config\n",
      "    /opt/conda/lib/python3.10/site-packages/numpy-2.2.4.dist-info/*\n",
      "    /opt/conda/lib/python3.10/site-packages/numpy.libs/libgfortran-040039e1-0352e75f.so.5.0.0\n",
      "    /opt/conda/lib/python3.10/site-packages/numpy.libs/libquadmath-96973f99-934c22de.so.0.0.0\n",
      "    /opt/conda/lib/python3.10/site-packages/numpy.libs/libscipy_openblas64_-6bb31eeb.so\n",
      "    /opt/conda/lib/python3.10/site-packages/numpy/*\n",
      "Proceed (Y/n)? "
     ]
    }
   ],
   "source": [
    "!pip uninstall numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a351e3ad-10b9-4294-8815-45653c7514c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#参数列表\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m kmeans_loaded \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../model/kmeans/kmeans_40_双手合并.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#分类文件夹根目录\u001b[39;00m\n\u001b[1;32m      3\u001b[0m all_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../SLR_dataset/seq_txt/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../SLR_dataset/kmeans_40_seq_双手合并_多头/\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load' is not defined"
     ]
    }
   ],
   "source": [
    "#参数列表\n",
    "kmeans_loaded = load('../model/kmeans/kmeans_40_双手合并.joblib') #分类文件夹根目录\n",
    "all_path = '../SLR_dataset/seq_txt/'\n",
    "save_path = '../SLR_dataset/kmeans_40_seq_双手合并_多头/'\n",
    "all_folder = [i for i in os.listdir(all_path)]\n",
    "quchong = False #去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fb3ecf74-a236-48f7-a8cf-fdcf21379941",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目录已存在：../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/\n"
     ]
    }
   ],
   "source": [
    "# 检查路径是否存在，不存在则创建（包括父目录）\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "    print(f\"目录已创建：{save_path}\")\n",
    "else:\n",
    "    print(f\"目录已存在：{save_path}\")\n",
    "def left_right_hand(data):\n",
    "    left = data[0:63]\n",
    "    right = data [63:]\n",
    "    return left,right\n",
    "def list_proLR(data):\n",
    "    #该函数用于将读取到的数据变成左右手格式\n",
    "    result = []\n",
    "    for i in data:\n",
    "        left,right = left_right_hand(i)\n",
    "        result+=[left,right]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "abc982b6-e49c-470c-a847-7d3801d907d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_consecutive_duplicates(sequence):\n",
    "    if not sequence:  # 空列表直接返回\n",
    "        return []\n",
    "    \n",
    "    result = [sequence[0]]  # 初始化结果列表，包含第一个元素\n",
    "    for num in sequence[1:]:  # 从第二个元素开始遍历\n",
    "        if num != result[-1]:  # 当前元素与结果中最后一个元素不同\n",
    "            result.append(num)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "327a21a0-2fe4-4b98-bc3f-75230b32c200",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_with_outlier(X, threshold=0.1):\n",
    "    # distances = kmeans_loaded.transform(X)  # 计算到所有中心的距离\n",
    "    # min_distances = np.min(distances, axis=1)\n",
    "    \n",
    "    # 分类结果（离群点设为0）\n",
    "    labels = kmeans_loaded.predict(X)\n",
    "    # labels[min_distances > threshold] = 999  # 阈值需根据数据分布调整\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6cd8037c-062b-4126-bd4a-e56076fef794",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def smart_clean(seq, max_repeats=1):\n",
    "    cleaned = []\n",
    "    i = 0\n",
    "    n = len(seq)\n",
    "    \n",
    "    while i < n:\n",
    "        best_pattern = None\n",
    "        best_length = 0\n",
    "        \n",
    "        # 检测从当前位置开始的最长重复模式（包括单个元素的重复）\n",
    "        for pattern_len in range(1, 5):  # 检测1到4长度的模式\n",
    "            if i + pattern_len > n:\n",
    "                continue\n",
    "                \n",
    "            pattern = seq[i:i+pattern_len]\n",
    "            repeats = 1\n",
    "            \n",
    "            # 计算重复次数\n",
    "            while i + (repeats + 1) * pattern_len <= n:\n",
    "                next_segment = seq[i + repeats * pattern_len : i + (repeats + 1) * pattern_len]\n",
    "                if next_segment == pattern:\n",
    "                    repeats += 1\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "            # 如果重复次数超过阈值，且比之前找到的模式更长，则更新最佳模式\n",
    "            if repeats > max_repeats and pattern_len * repeats > best_length:\n",
    "                best_pattern = pattern\n",
    "                best_length = pattern_len * repeats\n",
    "        \n",
    "        if best_pattern:\n",
    "            # 保留1次模式（如果是单个元素重复，只保留1次）\n",
    "            cleaned.extend(best_pattern)\n",
    "            i += best_length\n",
    "        else:\n",
    "            cleaned.append(seq[i])\n",
    "            i += 1\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2f74fa6d-45c1-4942-84fa-6dbabed3ffdf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000000.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000001.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000002.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000003.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000004.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000005.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000006.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000007.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000008.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000009.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000010.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000011.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000012.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000013.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000014.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000015.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000016.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000017.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000018.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000019.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000020.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000021.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000022.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000023.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000024.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000025.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000026.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000027.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000028.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000029.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000030.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000031.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000032.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000033.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000034.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000035.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000036.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000037.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000038.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000039.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000040.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000041.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000042.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000043.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000044.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000045.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000046.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000047.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000048.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000049.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000050.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000051.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000052.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000053.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000054.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000055.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000056.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000057.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000058.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000059.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000060.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000061.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000062.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000063.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000064.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000065.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000066.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000067.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000068.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000069.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000070.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000071.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000072.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000073.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000074.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000075.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000076.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000077.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000078.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000079.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000080.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000081.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000082.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000083.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000084.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000085.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000086.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000087.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000088.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000089.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000090.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000091.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000092.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000093.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000094.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000095.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000096.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000097.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000098.npy\n",
      "../SLR_dataset/kmeans_40_seq_双手合并_数据去重_三次滑动/000099.npy\n",
      "133\n"
     ]
    }
   ],
   "source": [
    "maxlen = 0\n",
    "for i in all_folder:\n",
    "    all_new_labels = []\n",
    "    folder = os.path.join(all_path,i)\n",
    "    file_name = [file for file in os.listdir(folder) if file.endswith('.avi')]\n",
    "    for j in file_name:\n",
    "        file_path = os.path.join(folder,j)\n",
    "        datalist = []\n",
    "        with open(file_path, 'r') as file:  # 以读取模式打开文件\n",
    "            for line in file:       # 逐行读取文件内容\n",
    "                # 按空格分割每一行，并将每个部分转换为浮点型\n",
    "                float_values = [float(x) for x in line.split()]\n",
    "                datalist.append(float_values)  # 将转换后的浮点型列表添加到 datalist\n",
    "        new_labels = predict_with_outlier(datalist)\n",
    "        # print(len(new_labels)) #212\n",
    "        # new_labels = [i for i in new_labels]\n",
    "        # # print(new_labels)\n",
    "        all_new_labels.append(new_labels)\n",
    "    all_new_labels = [[x for x in j if x != 999] for j in all_new_labels]\n",
    "    for cishu in range(3):\n",
    "        all_new_labels = [smart_clean(seq, max_repeats=1) for seq in all_new_labels]\n",
    "    # print(len(all_new_labels))\n",
    "    for seq in all_new_labels:\n",
    "        if len(seq) > maxlen:\n",
    "            maxlen = len(seq)\n",
    "    save_file_name = os.path.join(save_path,i)+'.npy'\n",
    "    save_data = np.array(all_new_labels,dtype=object)\n",
    "    # print(save_data)\n",
    "    np.save(save_file_name,save_data)\n",
    "    print(save_file_name)\n",
    "        # all_new_labels.append(remove_consecutive_duplicates(new_labels))\n",
    "print(maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9754c5d-7f11-4c73-a8bb-0bfdb108c4fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c31f11c4-a332-4ce3-bbb3-5fb1f4dfae49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in all_new_labels:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "670aff84-fa1a-475e-b671-72b65cfb6626",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_new_labels = [[x for x in j if x != 999] for j in all_new_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9ecf394f-c270-4a6d-9d02-5ce876029072",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_new_labels = [smart_clean(seq, max_repeats=1) for seq in all_new_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc79e827-65ab-45f1-91a2-898bbe6da23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0cd694a9-733f-4927-9aad-8b1d79fdd7e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b487b4f-ec31-490a-bdcc-f9ac5168b1f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleandata = []\n",
    "for i in all_new_labels:\n",
    "    cleandata.append(smart_clean(smart_clean(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8dc2a18-8256-4161-8417-37e1a2c806d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 33, 26, 15, 6, 2, 15, 6, 20, 38, 1, 4, 1, 4, 1, 4, 38, 4, 38, 4, 38, 4, 38, 4, 38, 4, 38, 20, 13, 38, 1, 4, 1, 4, 38, 4, 38, 20, 38, 4, 38, 1, 6, 1, 4, 1, 4, 10, 37, 27, 1, 20, 1, 38, 4, 38, 4, 38, 37, 38, 37, 10, 37, 10, 37, 10, 37, 6, 10, 37, 10, 37, 6]\n",
      "[6, 33, 15, 33, 29, 33, 6, 38, 1, 4, 1, 38, 20, 38, 6, 20, 6, 38, 6, 10, 37, 38, 4, 38, 4, 38, 6, 38, 1, 6, 1, 10, 27, 10, 37, 1, 4, 1, 4, 1, 4, 10, 37, 1, 4, 1, 37, 1, 17, 10, 37, 10, 37, 10, 37, 10, 37, 10, 1, 37, 10, 20, 1, 10, 20, 1, 10, 1, 37, 10, 37, 1, 6, 1, 6]\n",
      "[6, 33, 6, 2, 30, 25, 32, 25, 32, 8, 32, 10, 37, 1, 39, 28, 1, 24, 17, 36, 17, 0, 17, 0, 17, 0, 17, 0, 17, 2, 32, 2, 9, 2, 35, 5]\n",
      "[6, 33, 6, 1, 6, 10, 37, 10, 37, 10, 6, 10, 0, 17, 1, 17, 1, 39, 28, 24, 1, 24, 17, 0, 17, 36, 17, 0, 17, 0, 17, 2, 32, 2, 9, 2, 35, 5]\n",
      "[6, 33, 15, 2, 3, 2, 30, 25, 32, 8, 32, 10, 18, 10, 37, 1, 4, 39, 28, 24, 1, 24, 17, 0, 2, 8, 2, 35, 5]\n"
     ]
    }
   ],
   "source": [
    "for i in all_new_labels[:5]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b12a04d-9a58-406a-9be7-f67f8fdcb167",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 33, 26, 15, 6, 2, 15, 6, 20, 38, 1, 4, 38, 4, 38, 20, 13, 38, 1, 4, 1, 4, 38, 4, 38, 20, 38, 4, 38, 1, 6, 1, 4, 1, 4, 10, 37, 27, 1, 20, 1, 38, 4, 38, 4, 38, 37, 38, 37, 10, 37, 6, 10, 37, 10, 37, 6]\n",
      "[6, 33, 15, 33, 29, 33, 6, 38, 1, 4, 1, 38, 20, 38, 6, 20, 6, 38, 6, 10, 37, 38, 4, 38, 4, 38, 6, 38, 1, 6, 1, 10, 27, 10, 37, 1, 4, 10, 37, 1, 4, 1, 37, 1, 17, 10, 37, 10, 1, 37, 10, 20, 1, 10, 20, 1, 10, 1, 37, 10, 37, 1, 6, 1, 6]\n",
      "[6, 33, 6, 2, 30, 25, 32, 25, 32, 8, 32, 10, 37, 1, 39, 28, 1, 24, 17, 36, 17, 0, 17, 2, 32, 2, 9, 2, 35, 5]\n",
      "[6, 33, 6, 1, 6, 10, 37, 10, 37, 10, 6, 10, 0, 17, 1, 17, 1, 39, 28, 24, 1, 24, 17, 0, 17, 36, 17, 0, 17, 0, 17, 2, 32, 2, 9, 2, 35, 5]\n",
      "[6, 33, 15, 2, 3, 2, 30, 25, 32, 8, 32, 10, 18, 10, 37, 1, 4, 39, 28, 24, 1, 24, 17, 0, 2, 8, 2, 35, 5]\n"
     ]
    }
   ],
   "source": [
    "for i in cleandata[:5]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27588890-289f-4be6-ab71-bfe3938b6c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in all_folder:\n",
    "    all_new_labels = []\n",
    "    folder = os.path.join(all_path,i)\n",
    "    file_name = [file for file in os.listdir(folder) if file.endswith('.avi')]\n",
    "    for j in file_name:\n",
    "        file_path = os.path.join(folder,j)\n",
    "        datalist = []\n",
    "        with open(file_path, 'r') as file:  # 以读取模式打开文件\n",
    "            for line in file:       # 逐行读取文件内容\n",
    "                # 按空格分割每一行，并将每个部分转换为浮点型\n",
    "                float_values = [float(x) for x in line.split()]\n",
    "                datalist.append(float_values)  # 将转换后的浮点型列表添加到 datalist\n",
    "        new_labels = kmeans_loaded.predict(datalist)\n",
    "        all_new_labels.append(new_labels)\n",
    "    save_file_name = os.path.join(save_path,i)+'.npy'\n",
    "    save_data = np.array(all_new_labels,dtype=object)\n",
    "    # print(save_data)\n",
    "    np.save(save_file_name,save_data)\n",
    "    print(save_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a90a5de-df03-491f-97d9-148d997e2a81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../SLR_dataset/kmeans_300_seq_双手合并/000000.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000001.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000002.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000003.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000004.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000005.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000006.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000007.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000008.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000009.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000010.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000011.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000012.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000013.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000014.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000015.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000016.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000017.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000018.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000019.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000020.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000021.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000022.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000023.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000024.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000025.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000026.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000027.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000028.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000029.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000030.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000031.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000032.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000033.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000034.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000035.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000036.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000037.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000038.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000039.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000040.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000041.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000042.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000043.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000044.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000045.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000046.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000047.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000048.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000049.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000050.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000051.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000052.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000053.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000054.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000055.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000056.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000057.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000058.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000059.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000060.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000061.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000062.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000063.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000064.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000065.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000066.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000067.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000068.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000069.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000070.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000071.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000072.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000073.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000074.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000075.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000076.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000077.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000078.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000079.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000080.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000081.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000082.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000083.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000084.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000085.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000086.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000087.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000088.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000089.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000090.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000091.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000092.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000093.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000094.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000095.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000096.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000097.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000098.npy\n",
      "../SLR_dataset/kmeans_300_seq_双手合并/000099.npy\n"
     ]
    }
   ],
   "source": [
    "for i in all_folder:\n",
    "    all_new_labels = []\n",
    "    folder = os.path.join(all_path,i)\n",
    "    file_name = [file for file in os.listdir(folder) if file.endswith('.avi')]\n",
    "    for j in file_name:\n",
    "        file_path = os.path.join(folder,j)\n",
    "        datalist = []\n",
    "        with open(file_path, 'r') as file:  # 以读取模式打开文件\n",
    "            for line in file:       # 逐行读取文件内容\n",
    "                # 按空格分割每一行，并将每个部分转换为浮点型\n",
    "                float_values = [float(x) for x in line.split()]\n",
    "                datalist.append(float_values)  # 将转换后的浮点型列表添加到 datalist\n",
    "        new_labels = kmeans_loaded.predict(datalist)\n",
    "        all_new_labels.append(new_labels)\n",
    "    save_file_name = os.path.join(save_path,i)+'.npy'\n",
    "    save_data = np.array(all_new_labels,dtype=object)\n",
    "    # print(save_data)\n",
    "    np.save(save_file_name,save_data)\n",
    "    print(save_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f599e94b-eecb-4721-ae02-19d0fcd538da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../SLR_dataset/kmeans_100_seq_双手合并/000000.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m xxx \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../SLR_dataset/kmeans_100_seq_双手合并/000000.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../SLR_dataset/kmeans_100_seq_双手合并/000000.npy'"
     ]
    }
   ],
   "source": [
    "xxx = np.load('../SLR_dataset/kmeans_100_seq_双手合并/000000.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c580548d-21e2-4314-9fe1-db741fa052e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
